{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from common.trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConvNet:\n",
    "    def __init__(self,input_dim=(1,28,28),conv_param={'filter_num':30,'filter_size':5,'pad':0,'stride':1},\n",
    "        hidden_size=100,output_size=10,weight_init_std=0.01):\n",
    "        filter_num=conv_param['filter_num']\n",
    "        filter_size=conv_param['filter_size']\n",
    "        filter_pad=conv_param['pad']\n",
    "        filter_stride=conv_param['stride']\n",
    "        input_size=input_dim[1]\n",
    "        conv_output_size=(input_size-filter_size+2*filter_pad)/filter_stride+1\n",
    "        pool_output_size=int(filter_num*(conv_output_size/2)*(conv_output_size/2))\n",
    "        \n",
    "        self.params={}\n",
    "        self.params['W1']=weight_init_std*np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params['b1']=np.zeros(filter_num)\n",
    "        self.params['W2']=weight_init_std*np.random.randn(pool_output_size,hidden_size)\n",
    "        self.params['b2']=np.zeros(hidden_size)\n",
    "        self.params['W3']=weight_init_std*np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3']=np.zeros(output_size)\n",
    "        \n",
    "        self.layers=OrderedDict()\n",
    "        self.layers['Conv1']=Convolution(self.params['W1'],self.params['b1'],conv_param['stride'],conv_param['pad'])\n",
    "        self.layers['Relu1']=Relu()\n",
    "        self.layers['Pool1']=Pooling(pool_h=2,pool_w=2,stride=2)\n",
    "        self.layers['Affine1']=Affine(self.params['W2'],self.params['b2'])\n",
    "        self.layers['Relu2']=Relu()\n",
    "        self.layers['Affine2']=Affine(self.params['W3'],self.params['b3'])\n",
    "        \n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "        \n",
    "    def predict(self,x):\n",
    "        for layer in self.layers.values():\n",
    "            x=layer.forward(x)\n",
    "        return x\n",
    "    \n",
    "    def loss(self,x,t):\n",
    "        y=self.predict(x)\n",
    "        return self.last_layer.forward(y,t)\n",
    "    \n",
    "    def gradient(self,x,t):\n",
    "        #forward\n",
    "        self.loss(x,t)\n",
    "        \n",
    "        #backward\n",
    "        dout=1\n",
    "        dout=self.last_layer.backward(dout)\n",
    "        \n",
    "        layers=list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout=layer.backward(dout)\n",
    "            \n",
    "        #設定\n",
    "        grads={}\n",
    "        grads['W1']=self.layers['Conv1'].dW\n",
    "        grads['b1']=self.layers['Conv1'].db\n",
    "        grads['W2']=self.layers['Affine1'].dW\n",
    "        grads['b2']=self.layers['Affine1'].db\n",
    "        grads['W3']=self.layers['Affine2'].dW\n",
    "        grads['b3']=self.layers['Affine2'].db\n",
    "        \n",
    "        return grads\n",
    "    \n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        acc = 0.0\n",
    "        \n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt) \n",
    "        \n",
    "        return acc / x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.2996944501628542\n",
      "=== epoch:1, train acc:0.184, test acc:0.171 ===\n",
      "train loss:2.297125189337407\n",
      "train loss:2.2915254760237875\n",
      "train loss:2.289351101426434\n",
      "train loss:2.2828621577714934\n",
      "train loss:2.2746509310262613\n",
      "train loss:2.267807439844781\n",
      "train loss:2.252165395964182\n",
      "train loss:2.2188850993339706\n",
      "train loss:2.196465031514449\n",
      "train loss:2.1715962022496105\n",
      "train loss:2.154666817382836\n",
      "train loss:2.12155031156068\n",
      "train loss:2.0969921057716037\n",
      "train loss:1.989982121468179\n",
      "train loss:1.9549216612745424\n",
      "train loss:1.8565054768594027\n",
      "train loss:1.8458444222202217\n",
      "train loss:1.8207981841760654\n",
      "train loss:1.7444692496154217\n",
      "train loss:1.6310709004758144\n",
      "train loss:1.590690150249793\n",
      "train loss:1.5543812200978377\n",
      "train loss:1.3905767082363851\n",
      "train loss:1.306187135778635\n",
      "train loss:1.2740783912714884\n",
      "train loss:1.157249743389502\n",
      "train loss:1.1052938792390057\n",
      "train loss:1.0990502721889501\n",
      "train loss:0.9117739041610511\n",
      "train loss:0.9559192984403195\n",
      "train loss:0.8985784143635388\n",
      "train loss:0.8538699669726152\n",
      "train loss:0.7835077546175754\n",
      "train loss:0.8381866738436753\n",
      "train loss:0.8418482086472011\n",
      "train loss:0.7587310615076593\n",
      "train loss:0.8090846430829208\n",
      "train loss:0.6315219608485552\n",
      "train loss:0.8098489211356216\n",
      "train loss:0.763674691914895\n",
      "train loss:0.7577395586572878\n",
      "train loss:0.5266974964947437\n",
      "train loss:0.8080086420256487\n",
      "train loss:0.5497269905358939\n",
      "train loss:0.6617320053360386\n",
      "train loss:0.493381120577501\n",
      "train loss:0.5087819771562778\n",
      "train loss:0.6476414626145357\n",
      "train loss:0.6789215016926634\n",
      "train loss:0.7006146635727994\n",
      "train loss:0.5644295698854586\n",
      "train loss:0.5933135921106827\n",
      "train loss:0.5015017052507138\n",
      "train loss:0.5187384206901663\n",
      "train loss:0.6667974297012639\n",
      "train loss:0.6965856786183124\n",
      "train loss:0.6244617802280074\n",
      "train loss:0.5202349078831517\n",
      "train loss:0.6039416008237569\n",
      "train loss:0.5130689529183732\n",
      "train loss:0.530558190301462\n",
      "train loss:0.45700810577103945\n",
      "train loss:0.4933945302954108\n",
      "train loss:0.521277845643061\n",
      "train loss:0.565712508337603\n",
      "train loss:0.360258266019007\n",
      "train loss:0.35903638416057504\n",
      "train loss:0.5772397656889077\n",
      "train loss:0.4819490455426302\n",
      "train loss:0.43752383158603136\n",
      "train loss:0.3954165008761871\n",
      "train loss:0.4416194802112664\n",
      "train loss:0.6277436574561535\n",
      "train loss:0.4684213012905464\n",
      "train loss:0.3610692912005632\n",
      "train loss:0.47794158594806\n",
      "train loss:0.37015934062840666\n",
      "train loss:0.5903853556046293\n",
      "train loss:0.46729562416742326\n",
      "train loss:0.4239973850206855\n",
      "train loss:0.4292675172173063\n",
      "train loss:0.32867128114477184\n",
      "train loss:0.326925774029565\n",
      "train loss:0.4606148678356641\n",
      "train loss:0.48187729860756146\n",
      "train loss:0.3747607518275109\n",
      "train loss:0.4306049361251583\n",
      "train loss:0.4361522774313473\n",
      "train loss:0.42270257471338624\n",
      "train loss:0.5538071385365909\n",
      "train loss:0.4281869195375002\n",
      "train loss:0.3045256601496482\n",
      "train loss:0.3807450960245052\n",
      "train loss:0.4707296921115473\n",
      "train loss:0.4692392675465995\n",
      "train loss:0.4227806184248547\n",
      "train loss:0.4035489383247486\n",
      "train loss:0.6501223763121559\n",
      "train loss:0.3858019845617599\n",
      "train loss:0.42163075805862965\n",
      "train loss:0.4719899205008794\n",
      "train loss:0.3419026023638174\n",
      "train loss:0.33762216848983967\n",
      "train loss:0.47678756253993737\n",
      "train loss:0.2899625529203743\n",
      "train loss:0.24616493273331888\n",
      "train loss:0.4074041592923474\n",
      "train loss:0.2916677577054036\n",
      "train loss:0.2793185240115542\n",
      "train loss:0.31592146468277177\n",
      "train loss:0.38216099343153787\n",
      "train loss:0.44247821898463563\n",
      "train loss:0.4390395691211814\n",
      "train loss:0.3907671729999552\n",
      "train loss:0.4284157197398279\n",
      "train loss:0.23944041334034452\n",
      "train loss:0.3504601428533079\n",
      "train loss:0.4042300539140197\n",
      "train loss:0.4036880135991343\n",
      "train loss:0.4137929670527277\n",
      "train loss:0.3547756605760991\n",
      "train loss:0.3672941806832987\n",
      "train loss:0.30083353086230175\n",
      "train loss:0.3039147347646344\n",
      "train loss:0.4510658640028115\n",
      "train loss:0.28608744436596506\n",
      "train loss:0.3357638291378606\n",
      "train loss:0.37977054540687083\n",
      "train loss:0.2902782285909952\n",
      "train loss:0.32141200562688027\n",
      "train loss:0.2149994429936888\n",
      "train loss:0.4993021549634348\n",
      "train loss:0.2655851272142251\n",
      "train loss:0.3823502725983437\n",
      "train loss:0.28529489603738356\n",
      "train loss:0.3047588211226829\n",
      "train loss:0.164837330457286\n",
      "train loss:0.2925103246937621\n",
      "train loss:0.40217900847314003\n",
      "train loss:0.220985940671652\n",
      "train loss:0.40639199523792696\n",
      "train loss:0.2719327048658318\n",
      "train loss:0.2884793812419335\n",
      "train loss:0.27380373750802295\n",
      "train loss:0.3058215753120151\n",
      "train loss:0.46543924067717746\n",
      "train loss:0.40191752242376594\n",
      "train loss:0.3137793091497325\n",
      "train loss:0.33966175506860014\n",
      "train loss:0.24995330825178083\n",
      "train loss:0.24568812607268914\n",
      "train loss:0.3469478850962673\n",
      "train loss:0.36281760055949974\n",
      "train loss:0.24266631998416754\n",
      "train loss:0.3525636810621642\n",
      "train loss:0.43277549204614857\n",
      "train loss:0.3446145759427958\n",
      "train loss:0.42256947525052935\n",
      "train loss:0.42383776534939216\n",
      "train loss:0.16872195029679724\n",
      "train loss:0.44414996131052675\n",
      "train loss:0.3020039982703022\n",
      "train loss:0.18655482776159787\n",
      "train loss:0.28002935365441967\n",
      "train loss:0.30527244605959114\n",
      "train loss:0.4295749569626238\n",
      "train loss:0.3675397684072408\n",
      "train loss:0.2751255926699756\n",
      "train loss:0.2060981633729315\n",
      "train loss:0.29468734420223425\n",
      "train loss:0.470494512252305\n",
      "train loss:0.30346681446562507\n",
      "train loss:0.26234614409980284\n",
      "train loss:0.5371361491943034\n",
      "train loss:0.39963727167829416\n",
      "train loss:0.2748669708686761\n",
      "train loss:0.3134484892665787\n",
      "train loss:0.25133013166250245\n",
      "train loss:0.36089344765327214\n",
      "train loss:0.14892409055628492\n",
      "train loss:0.20043199342623794\n",
      "train loss:0.24635133639399784\n",
      "train loss:0.3491491672055902\n",
      "train loss:0.27298319542772087\n",
      "train loss:0.599185203569501\n",
      "train loss:0.2550273307632701\n",
      "train loss:0.2612360883082959\n",
      "train loss:0.4149209894017128\n",
      "train loss:0.30145306186932436\n",
      "train loss:0.270115106049729\n",
      "train loss:0.3782249108913319\n",
      "train loss:0.1957110261779727\n",
      "train loss:0.21174857329890245\n",
      "train loss:0.16318515968230402\n",
      "train loss:0.28176894833066396\n",
      "train loss:0.28933981324008334\n",
      "train loss:0.28882788529991354\n",
      "train loss:0.22441710417255845\n",
      "train loss:0.22955085971670497\n",
      "train loss:0.20651396615630027\n",
      "train loss:0.1330750377471201\n",
      "train loss:0.2640033791963683\n",
      "train loss:0.2701194083176518\n",
      "train loss:0.25071344474844676\n",
      "train loss:0.2806307724894004\n",
      "train loss:0.3350789798268751\n",
      "train loss:0.3562010760114493\n",
      "train loss:0.27141907537966947\n",
      "train loss:0.2666711933595954\n",
      "train loss:0.34690532028385285\n",
      "train loss:0.23077103898091733\n",
      "train loss:0.20589267458019944\n",
      "train loss:0.47631849091134737\n",
      "train loss:0.21310257713423603\n",
      "train loss:0.4383210483067313\n",
      "train loss:0.2942712414515843\n",
      "train loss:0.5977054017534186\n",
      "train loss:0.14206187356441227\n",
      "train loss:0.2782775284700236\n",
      "train loss:0.3255568464052175\n",
      "train loss:0.3809034503898257\n",
      "train loss:0.21838539082170663\n",
      "train loss:0.1848175622224003\n",
      "train loss:0.1962218390115164\n",
      "train loss:0.4653136959664939\n",
      "train loss:0.2901268828971097\n",
      "train loss:0.3105606491930766\n",
      "train loss:0.3644256176394902\n",
      "train loss:0.2952642564512729\n",
      "train loss:0.2779823791327022\n",
      "train loss:0.21932055465106362\n",
      "train loss:0.23293242412099538\n",
      "train loss:0.24430132952198363\n",
      "train loss:0.2335380998775183\n",
      "train loss:0.24011132749061256\n",
      "train loss:0.27115901029862455\n",
      "train loss:0.25293410280397766\n",
      "train loss:0.30848279880972423\n",
      "train loss:0.27961035584083355\n",
      "train loss:0.35727530637082333\n",
      "train loss:0.29707940955467166\n",
      "train loss:0.43642489471674506\n",
      "train loss:0.20107299416539676\n",
      "train loss:0.21081176634304602\n",
      "train loss:0.29177070869482463\n",
      "train loss:0.22703146170277136\n",
      "train loss:0.19979750866334242\n",
      "train loss:0.21332473476271666\n",
      "train loss:0.2776700583387737\n",
      "train loss:0.38645217307984503\n",
      "train loss:0.26738788520831497\n",
      "train loss:0.29870854268759434\n",
      "train loss:0.24511298164924317\n",
      "train loss:0.3092186329926864\n",
      "train loss:0.23224643520985772\n",
      "train loss:0.24948969860616244\n",
      "train loss:0.23473134546218977\n",
      "train loss:0.19950426949063094\n",
      "train loss:0.19116829814360364\n",
      "train loss:0.36308128049667227\n",
      "train loss:0.3225623554101609\n",
      "train loss:0.31910882592494877\n",
      "train loss:0.23411761619073793\n",
      "train loss:0.27210375023708694\n",
      "train loss:0.2528766987662786\n",
      "train loss:0.19016223883589564\n",
      "train loss:0.2549233447208461\n",
      "train loss:0.18353202376533048\n",
      "train loss:0.28569201513890763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.2958131672780665\n",
      "train loss:0.24275559475198602\n",
      "train loss:0.1498061674655117\n",
      "train loss:0.3680902444431395\n",
      "train loss:0.12228105066328247\n",
      "train loss:0.21555055089458253\n",
      "train loss:0.17429048040002956\n",
      "train loss:0.23437272739895884\n",
      "train loss:0.21304362435852287\n",
      "train loss:0.19443882724487113\n",
      "train loss:0.20801336405238888\n",
      "train loss:0.10893435721369232\n",
      "train loss:0.2874535799871026\n",
      "train loss:0.2508384096091876\n",
      "train loss:0.19036643482765084\n",
      "train loss:0.22697974641385116\n",
      "train loss:0.23829975834580164\n",
      "train loss:0.3829347037884582\n",
      "train loss:0.09812684097789923\n",
      "train loss:0.1577727107474136\n",
      "train loss:0.19830784767862666\n",
      "train loss:0.2800140096528337\n",
      "train loss:0.30904565110544346\n",
      "train loss:0.2238364145924308\n",
      "train loss:0.12875803462118418\n",
      "train loss:0.29304840323855635\n",
      "train loss:0.24651253138588597\n",
      "train loss:0.2251621615416145\n",
      "train loss:0.2027756228121057\n",
      "train loss:0.14924597654188676\n",
      "train loss:0.28416031158775273\n",
      "train loss:0.24913334748984833\n",
      "train loss:0.32779892536101857\n",
      "train loss:0.23519599827577142\n",
      "train loss:0.12873460564187267\n",
      "train loss:0.2140573475366901\n",
      "train loss:0.1110874995268585\n",
      "train loss:0.15939859725586872\n",
      "train loss:0.24282245351800996\n",
      "train loss:0.15212690443842541\n",
      "train loss:0.2581210976487887\n",
      "train loss:0.05843701611513139\n",
      "train loss:0.12746382618560795\n",
      "train loss:0.19808187487690557\n",
      "train loss:0.15627738733123336\n",
      "train loss:0.21995498059856625\n",
      "train loss:0.31006409300576654\n",
      "train loss:0.3143923432938558\n",
      "train loss:0.22091759981390624\n",
      "train loss:0.10717908846370866\n",
      "train loss:0.15129113690464244\n",
      "train loss:0.18899949614421874\n",
      "train loss:0.1964092038878363\n",
      "train loss:0.12201333996857189\n",
      "train loss:0.2095680507117761\n",
      "train loss:0.21522319327726\n",
      "train loss:0.095677888595786\n",
      "train loss:0.26577068975591145\n",
      "train loss:0.2615150347383321\n",
      "train loss:0.16888767731589188\n",
      "train loss:0.1714947655009848\n",
      "train loss:0.11543781087727584\n",
      "train loss:0.10437412551401815\n",
      "train loss:0.26076656212085125\n",
      "train loss:0.18345505640731222\n",
      "train loss:0.22024860824169604\n",
      "train loss:0.25384896217842107\n",
      "train loss:0.19495791027272383\n",
      "train loss:0.28908520310105223\n",
      "train loss:0.16397007205263742\n",
      "train loss:0.15916012467549678\n",
      "train loss:0.32509525314680104\n",
      "train loss:0.21597550152088504\n",
      "train loss:0.14473873480581984\n",
      "train loss:0.1505641683453091\n",
      "train loss:0.1178705633518319\n",
      "train loss:0.11615943861654798\n",
      "train loss:0.23154176509641064\n",
      "train loss:0.26237059227041115\n",
      "train loss:0.09451493109571028\n",
      "train loss:0.28297436662510955\n",
      "train loss:0.17721751947864242\n",
      "train loss:0.19176884917661371\n",
      "train loss:0.1804134301456387\n",
      "train loss:0.12122661750719627\n",
      "train loss:0.18611831270416115\n",
      "train loss:0.21847964606339818\n",
      "train loss:0.1393781173013256\n",
      "train loss:0.10919244098407217\n",
      "train loss:0.32525111867413364\n",
      "train loss:0.4467339706783768\n",
      "train loss:0.20004186813476188\n",
      "train loss:0.15483260968138235\n",
      "train loss:0.2856983882945904\n",
      "train loss:0.13487970866135052\n",
      "train loss:0.12025518179737846\n",
      "train loss:0.17815830354417728\n",
      "train loss:0.1469976186455502\n",
      "train loss:0.12573386869190212\n",
      "train loss:0.1776223128552151\n",
      "train loss:0.20347183314089257\n",
      "train loss:0.22662717473159144\n",
      "train loss:0.13623800217115198\n",
      "train loss:0.1439779177804544\n",
      "train loss:0.2807444507003679\n",
      "train loss:0.13210224962385697\n",
      "train loss:0.21654768428619126\n",
      "train loss:0.22927916855803954\n",
      "train loss:0.14857161571668198\n",
      "train loss:0.25626780669178617\n",
      "train loss:0.2119803058618307\n",
      "train loss:0.11662204422919815\n",
      "train loss:0.33307971744267495\n",
      "train loss:0.13200368573277496\n",
      "train loss:0.15293182416974496\n",
      "train loss:0.2936087649053981\n",
      "train loss:0.18194345693108868\n",
      "train loss:0.20246655742118988\n",
      "train loss:0.15537752144104572\n",
      "train loss:0.09413716660073104\n",
      "train loss:0.09699350684507697\n",
      "train loss:0.29104774673522527\n",
      "train loss:0.2051981645858405\n",
      "train loss:0.20336882745338447\n",
      "train loss:0.07937990705435931\n",
      "train loss:0.2697532792878393\n",
      "train loss:0.14768911234750504\n",
      "train loss:0.2346836272390796\n",
      "train loss:0.25304704722023286\n",
      "train loss:0.058442917492576074\n",
      "train loss:0.12346243621527783\n",
      "train loss:0.1615819009442412\n",
      "train loss:0.3607912638706985\n",
      "train loss:0.14127305952615843\n",
      "train loss:0.09171404998597478\n",
      "train loss:0.18748210274325278\n",
      "train loss:0.18962096839242967\n",
      "train loss:0.1933490680756191\n",
      "train loss:0.15926602934338244\n",
      "train loss:0.2888197895467198\n",
      "train loss:0.2406794092355418\n",
      "train loss:0.2130882881786613\n",
      "train loss:0.2873271788140939\n",
      "train loss:0.16584620227885835\n",
      "train loss:0.10217788631619865\n",
      "train loss:0.2136421545072283\n",
      "train loss:0.24163507952040256\n",
      "train loss:0.07747721263272847\n",
      "train loss:0.11055252717714475\n",
      "train loss:0.2085997296127426\n",
      "train loss:0.1381774061689744\n",
      "train loss:0.1549608098054218\n",
      "train loss:0.17315201678277325\n",
      "train loss:0.16064333198750266\n",
      "train loss:0.17281533055905654\n",
      "train loss:0.17184871135355173\n",
      "train loss:0.24464284131365388\n",
      "train loss:0.26331413586967656\n",
      "train loss:0.28554299712002384\n",
      "train loss:0.18343514140504869\n",
      "train loss:0.18251379012824753\n",
      "train loss:0.16312159603117238\n",
      "train loss:0.11012769913209848\n",
      "train loss:0.19961279161220927\n",
      "train loss:0.0908378442267777\n",
      "train loss:0.19217714930862295\n",
      "train loss:0.1632100512489971\n",
      "train loss:0.23313940427807828\n",
      "train loss:0.12383632462503134\n",
      "train loss:0.13616746165453014\n",
      "train loss:0.2492684304028959\n",
      "train loss:0.3540896520984743\n",
      "train loss:0.37077444948179517\n",
      "train loss:0.10564946374675888\n",
      "train loss:0.08891506523278184\n",
      "train loss:0.13844497975424383\n",
      "train loss:0.14598667175228916\n",
      "train loss:0.31176297272607856\n",
      "train loss:0.17962128109874825\n",
      "train loss:0.2196790885954399\n",
      "train loss:0.22710798813486555\n",
      "train loss:0.28522647993635425\n",
      "train loss:0.19246596992411902\n",
      "train loss:0.09045590299910587\n",
      "train loss:0.06823524167648988\n",
      "train loss:0.23176693787207497\n",
      "train loss:0.16764652042814074\n",
      "train loss:0.14681369527446275\n",
      "train loss:0.09172017851306188\n",
      "train loss:0.19544385909476966\n",
      "train loss:0.18942196154579236\n",
      "train loss:0.18550049263191973\n",
      "train loss:0.08873548927907732\n",
      "train loss:0.21070847105045934\n",
      "train loss:0.18658697109610323\n",
      "train loss:0.13652097496236848\n",
      "train loss:0.11862756052894202\n",
      "train loss:0.23664559969892685\n",
      "train loss:0.07005118253988976\n",
      "train loss:0.18728445933514049\n",
      "train loss:0.13940677433112117\n",
      "train loss:0.2217766436144355\n",
      "train loss:0.3032041949440354\n",
      "train loss:0.11406386043845176\n",
      "train loss:0.23240941506539717\n",
      "train loss:0.23095514218420135\n",
      "train loss:0.165859340303877\n",
      "train loss:0.12180717950267475\n",
      "train loss:0.19059629047257495\n",
      "train loss:0.0767173474723708\n",
      "train loss:0.16257365583933747\n",
      "train loss:0.13268289961501925\n",
      "train loss:0.23195373680225637\n",
      "train loss:0.1728521129290164\n",
      "train loss:0.14470793796401005\n",
      "train loss:0.1799164839682863\n",
      "train loss:0.25031002256746643\n",
      "train loss:0.14011214724297616\n",
      "train loss:0.13128964371522642\n",
      "train loss:0.1895300101649012\n",
      "train loss:0.18863047325865093\n",
      "train loss:0.2600958525047239\n",
      "train loss:0.06323611415269798\n",
      "train loss:0.15526672022214194\n",
      "train loss:0.08075775754104997\n",
      "train loss:0.12818196167754556\n",
      "train loss:0.22485751568427703\n",
      "train loss:0.10286223363315428\n",
      "train loss:0.19193067874486258\n",
      "train loss:0.10724760391897484\n",
      "train loss:0.10848273246262305\n",
      "train loss:0.06334195738811033\n",
      "train loss:0.14906011943683478\n",
      "train loss:0.08508694206449727\n",
      "train loss:0.21570851231251986\n",
      "train loss:0.21735944356013753\n",
      "train loss:0.19744463586971236\n",
      "train loss:0.12160674479673504\n",
      "train loss:0.135690612077444\n",
      "train loss:0.17928510634101713\n",
      "train loss:0.1346701662683726\n",
      "train loss:0.18134599522084818\n",
      "train loss:0.15686545850203693\n",
      "train loss:0.15182110159003273\n",
      "train loss:0.15343414160619914\n",
      "train loss:0.1700002782131345\n",
      "train loss:0.08999176072388648\n",
      "train loss:0.13548919058583558\n",
      "train loss:0.15111427430345528\n",
      "train loss:0.30145394497790207\n",
      "train loss:0.15321949251020733\n",
      "train loss:0.14499397903887423\n",
      "train loss:0.14391722568385104\n",
      "train loss:0.2665212497811456\n",
      "train loss:0.13524961771782334\n",
      "train loss:0.21074276532263655\n",
      "train loss:0.12240861451315321\n",
      "train loss:0.1765669282960938\n",
      "train loss:0.1782180742434982\n",
      "train loss:0.10373608488493469\n",
      "train loss:0.12998423615359217\n",
      "train loss:0.11065753221666964\n",
      "train loss:0.10565761101337716\n",
      "train loss:0.24889019664181375\n",
      "train loss:0.11377716459453124\n",
      "train loss:0.10929064650223876\n",
      "train loss:0.085694470247158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.09444828317495917\n",
      "train loss:0.15721155552419538\n",
      "train loss:0.1395794635859442\n",
      "train loss:0.07764360184599281\n",
      "train loss:0.0859925086140345\n",
      "train loss:0.07699159255577405\n",
      "train loss:0.16232174471910304\n",
      "train loss:0.09998294749952949\n",
      "train loss:0.18083921062936592\n",
      "train loss:0.1800298233824561\n",
      "train loss:0.1203360422446374\n",
      "train loss:0.17671479798633197\n",
      "train loss:0.14613334040467463\n",
      "train loss:0.10619408611457958\n",
      "train loss:0.13755208752161732\n",
      "train loss:0.06573460152759789\n",
      "train loss:0.1770724152810876\n",
      "train loss:0.16928818083131758\n",
      "train loss:0.10403802111290121\n",
      "train loss:0.21112001547799916\n",
      "train loss:0.23778428140705624\n",
      "train loss:0.17937852452878705\n",
      "train loss:0.2058324129646264\n",
      "train loss:0.1797547006700411\n",
      "train loss:0.14434099390127456\n",
      "train loss:0.12255320111642522\n",
      "train loss:0.14948071757769968\n",
      "train loss:0.12812963639208302\n",
      "train loss:0.11361802991657491\n",
      "train loss:0.19497032803123462\n",
      "train loss:0.09855491708258925\n",
      "train loss:0.08173694720713057\n",
      "train loss:0.12252265000739403\n",
      "train loss:0.14993807487339741\n",
      "train loss:0.11261560437109708\n",
      "train loss:0.15435207695992845\n",
      "train loss:0.0858124722814284\n",
      "train loss:0.11070508039585186\n",
      "train loss:0.1280538133896501\n",
      "train loss:0.17654760512340378\n",
      "train loss:0.06242996779134703\n",
      "train loss:0.12948174173419136\n",
      "train loss:0.24300702077221392\n",
      "train loss:0.06014076534427834\n",
      "train loss:0.18764110139363768\n",
      "train loss:0.1908995841968399\n",
      "train loss:0.08253468612261448\n",
      "train loss:0.16380959057455272\n",
      "train loss:0.12596996446438724\n",
      "train loss:0.20318461458482578\n",
      "train loss:0.1844546466454561\n",
      "train loss:0.12087794865724984\n",
      "train loss:0.26827219575984224\n",
      "train loss:0.09843271873470164\n",
      "train loss:0.1029874467140222\n",
      "train loss:0.21602311114260278\n",
      "train loss:0.044470318862706026\n",
      "train loss:0.2372529921095505\n",
      "train loss:0.17966978539737488\n",
      "train loss:0.24701851172589756\n",
      "train loss:0.15265532230603546\n",
      "train loss:0.1797733715378016\n",
      "train loss:0.1390864735288343\n",
      "train loss:0.11434559071142283\n",
      "=== epoch:2, train acc:0.964, test acc:0.966 ===\n",
      "train loss:0.07912420830609097\n",
      "train loss:0.23696309877949331\n",
      "train loss:0.11436266618920135\n",
      "train loss:0.09070575519580036\n",
      "train loss:0.14872083744848152\n",
      "train loss:0.12709826046136694\n",
      "train loss:0.11976269231499934\n",
      "train loss:0.18610104619701545\n",
      "train loss:0.08299764392949265\n",
      "train loss:0.18648008140049155\n",
      "train loss:0.11865074753427135\n",
      "train loss:0.09782999239726647\n",
      "train loss:0.08634002663846303\n",
      "train loss:0.11877784942341844\n",
      "train loss:0.16288870103939865\n",
      "train loss:0.052108628614950546\n",
      "train loss:0.17158808288843772\n",
      "train loss:0.11526578555771293\n",
      "train loss:0.09449818638927901\n",
      "train loss:0.12243388625108385\n",
      "train loss:0.0937965794903119\n",
      "train loss:0.09665205865490036\n",
      "train loss:0.14719622971433077\n",
      "train loss:0.055370806164548994\n",
      "train loss:0.09357085772791525\n",
      "train loss:0.0755288730001763\n",
      "train loss:0.1561630302193586\n",
      "train loss:0.2230956996252369\n",
      "train loss:0.07690757738035414\n",
      "train loss:0.23774528067655595\n",
      "train loss:0.1724479258794732\n",
      "train loss:0.1816408503551898\n",
      "train loss:0.11845422559373038\n",
      "train loss:0.21692102439808159\n",
      "train loss:0.10787076756588405\n",
      "train loss:0.18332864571455038\n",
      "train loss:0.1014237828454213\n",
      "train loss:0.07506183505012436\n",
      "train loss:0.08680720029910334\n",
      "train loss:0.14483529971427297\n",
      "train loss:0.07758023223383191\n",
      "train loss:0.06085291750884712\n",
      "train loss:0.11652064878348467\n",
      "train loss:0.10666882340042017\n",
      "train loss:0.135296244746671\n",
      "train loss:0.057484109273699124\n",
      "train loss:0.11159254413851336\n",
      "train loss:0.1281126439026828\n",
      "train loss:0.0967244224473081\n",
      "train loss:0.07131968272195566\n",
      "train loss:0.12561327821238064\n",
      "train loss:0.13817851401088446\n",
      "train loss:0.14317827928390053\n",
      "train loss:0.12913213230868625\n",
      "train loss:0.05762842942293719\n",
      "train loss:0.0850889537620186\n",
      "train loss:0.06587104045608845\n",
      "train loss:0.106489434852162\n",
      "train loss:0.17485842571977434\n",
      "train loss:0.23862840104926075\n",
      "train loss:0.07711292208929238\n",
      "train loss:0.2002451798750265\n",
      "train loss:0.15611684330019704\n",
      "train loss:0.06146736942687988\n",
      "train loss:0.13458516338280246\n",
      "train loss:0.07672560182458549\n",
      "train loss:0.12049383206577775\n",
      "train loss:0.05739554864286509\n",
      "train loss:0.11082317590326342\n",
      "train loss:0.2511669417675872\n",
      "train loss:0.08318997748368238\n",
      "train loss:0.0850063037632712\n",
      "train loss:0.1253581733602467\n",
      "train loss:0.10878843190293716\n",
      "train loss:0.16931706683435288\n",
      "train loss:0.09060621761140145\n",
      "train loss:0.11808612800640113\n",
      "train loss:0.05572670453554661\n",
      "train loss:0.10203471635500644\n",
      "train loss:0.10134276870807897\n",
      "train loss:0.07711941135484428\n",
      "train loss:0.29050508662383595\n",
      "train loss:0.16871313170779603\n",
      "train loss:0.2032072847986235\n",
      "train loss:0.14788893933022595\n",
      "train loss:0.11017480061007678\n",
      "train loss:0.07266368795253547\n",
      "train loss:0.07129505604714095\n",
      "train loss:0.11149980502441803\n",
      "train loss:0.13013845231622895\n",
      "train loss:0.19914441471768726\n",
      "train loss:0.12393585499164526\n",
      "train loss:0.08404985432581044\n",
      "train loss:0.0966401654303429\n",
      "train loss:0.12685644085184483\n",
      "train loss:0.2482590142378568\n",
      "train loss:0.10068679398175683\n",
      "train loss:0.21885593591409275\n",
      "train loss:0.14424673237019647\n",
      "train loss:0.08367490455157257\n",
      "train loss:0.10097438015346695\n",
      "train loss:0.11370135129533343\n",
      "train loss:0.0892177793308962\n",
      "train loss:0.09169475724693321\n",
      "train loss:0.10845084816418124\n",
      "train loss:0.1951715158171436\n",
      "train loss:0.1373634230620898\n",
      "train loss:0.09549396959147707\n",
      "train loss:0.1076618768932149\n",
      "train loss:0.1130838219423903\n",
      "train loss:0.12089913551124587\n",
      "train loss:0.11396582625994293\n",
      "train loss:0.14116186732184755\n",
      "train loss:0.1816665558349772\n",
      "train loss:0.07754068708829343\n",
      "train loss:0.18752868088075014\n",
      "train loss:0.23754732896326888\n",
      "train loss:0.09147347751786711\n",
      "train loss:0.05002871768608153\n",
      "train loss:0.09587497747453717\n",
      "train loss:0.10228430029327219\n",
      "train loss:0.051043244717690686\n",
      "train loss:0.08468605978890072\n",
      "train loss:0.10411994045413973\n",
      "train loss:0.1426433385868571\n",
      "train loss:0.08170466094508987\n",
      "train loss:0.06877859883045699\n",
      "train loss:0.13267676793531663\n",
      "train loss:0.04233897820687223\n",
      "train loss:0.05347703367172293\n",
      "train loss:0.12128489567965303\n",
      "train loss:0.15854589524554266\n",
      "train loss:0.09155886128359243\n",
      "train loss:0.17237410006725695\n",
      "train loss:0.09621825405150798\n",
      "train loss:0.049912357604488415\n",
      "train loss:0.05421490764316094\n",
      "train loss:0.1496207878758142\n",
      "train loss:0.1427133715071753\n",
      "train loss:0.11774805246064494\n",
      "train loss:0.09306401291900665\n",
      "train loss:0.11208297259693807\n",
      "train loss:0.19492820076119213\n",
      "train loss:0.044124402089983514\n",
      "train loss:0.12717653368133688\n",
      "train loss:0.08507155243833411\n",
      "train loss:0.12128428304278747\n",
      "train loss:0.15185030774283118\n",
      "train loss:0.15194451220159885\n",
      "train loss:0.11271040756086366\n",
      "train loss:0.10595386597913495\n",
      "train loss:0.06187118007743314\n",
      "train loss:0.06862075237553242\n",
      "train loss:0.09075371050814976\n",
      "train loss:0.1440767774808853\n",
      "train loss:0.0839770853852296\n",
      "train loss:0.0699367951137964\n",
      "train loss:0.16070615786785986\n",
      "train loss:0.12698508790161203\n",
      "train loss:0.04515808532613158\n",
      "train loss:0.07036667126163744\n",
      "train loss:0.25929866748445085\n",
      "train loss:0.05299210434390651\n",
      "train loss:0.08809248952732637\n",
      "train loss:0.18174892189748784\n",
      "train loss:0.17862742414467242\n",
      "train loss:0.10508109366452265\n",
      "train loss:0.11825185058458881\n",
      "train loss:0.07363316340349163\n",
      "train loss:0.10860579058079019\n",
      "train loss:0.08169608924645468\n",
      "train loss:0.13469377179064565\n",
      "train loss:0.11352138557395365\n",
      "train loss:0.21171650433484207\n",
      "train loss:0.09738877060525851\n",
      "train loss:0.09931025100155073\n",
      "train loss:0.09362320724330328\n",
      "train loss:0.06959418664594182\n",
      "train loss:0.08273130317956454\n",
      "train loss:0.1296036373415865\n",
      "train loss:0.14355719346870285\n",
      "train loss:0.08060074915407495\n",
      "train loss:0.10734292752544118\n",
      "train loss:0.11426041650016906\n",
      "train loss:0.11479403034420757\n",
      "train loss:0.1723507119911304\n",
      "train loss:0.2119343574805692\n",
      "train loss:0.09781839532550082\n",
      "train loss:0.06507216365655738\n",
      "train loss:0.0822436669955312\n",
      "train loss:0.06925634223844562\n",
      "train loss:0.07265214521950819\n",
      "train loss:0.09753372231323648\n",
      "train loss:0.13901650774174176\n",
      "train loss:0.0821922489435703\n",
      "train loss:0.1510290162300917\n",
      "train loss:0.0485585888341938\n",
      "train loss:0.10098691336142092\n",
      "train loss:0.15131079992774019\n",
      "train loss:0.06552695225204165\n",
      "train loss:0.1264123585282215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.09514659964440005\n",
      "train loss:0.07630888062893551\n",
      "train loss:0.18343295041905594\n",
      "train loss:0.20642922301856473\n",
      "train loss:0.06036694289321521\n",
      "train loss:0.17787435421708522\n",
      "train loss:0.1594630846907751\n",
      "train loss:0.12817615010201416\n",
      "train loss:0.13189393008951572\n",
      "train loss:0.04896220594320317\n",
      "train loss:0.046799861337555315\n",
      "train loss:0.09342179483689358\n",
      "train loss:0.07644157635261757\n",
      "train loss:0.05213834787737712\n",
      "train loss:0.04877598446953237\n",
      "train loss:0.09263494591011623\n",
      "train loss:0.10056466015667981\n",
      "train loss:0.033035041212752\n",
      "train loss:0.15383295404254263\n",
      "train loss:0.15086745311009328\n",
      "train loss:0.06901158119926074\n",
      "train loss:0.09860138768269153\n",
      "train loss:0.0757178033054469\n",
      "train loss:0.09408867386767866\n",
      "train loss:0.04049061165513189\n",
      "train loss:0.02983416039372601\n",
      "train loss:0.0489156803143959\n",
      "train loss:0.056642067903609795\n",
      "train loss:0.0924306095429564\n",
      "train loss:0.08523147307947442\n",
      "train loss:0.03585443538485464\n",
      "train loss:0.08867235660638334\n",
      "train loss:0.04550419010625508\n",
      "train loss:0.1588469011750653\n",
      "train loss:0.08439021982013757\n",
      "train loss:0.0844437223986149\n",
      "train loss:0.07940582455953343\n",
      "train loss:0.059078969285190144\n",
      "train loss:0.13134133557973107\n",
      "train loss:0.04088191587859362\n",
      "train loss:0.0395170436820712\n",
      "train loss:0.08327306977250463\n",
      "train loss:0.09357565364947597\n",
      "train loss:0.08546778939300674\n",
      "train loss:0.04563663962104293\n",
      "train loss:0.11798451491479194\n",
      "train loss:0.12490221199224771\n",
      "train loss:0.07105860090843774\n",
      "train loss:0.05502138672728874\n",
      "train loss:0.11354546777611044\n",
      "train loss:0.0223974486921\n",
      "train loss:0.052664557962510364\n",
      "train loss:0.023375100522072593\n",
      "train loss:0.08719299258836836\n",
      "train loss:0.11310803990508317\n",
      "train loss:0.1565890642764529\n",
      "train loss:0.08066325158171207\n",
      "train loss:0.07464227609988217\n",
      "train loss:0.09735009211628168\n",
      "train loss:0.09819037211915195\n",
      "train loss:0.10124913281063193\n",
      "train loss:0.1310296445230316\n",
      "train loss:0.05308471661321557\n",
      "train loss:0.059374016562162325\n",
      "train loss:0.07364725914516593\n",
      "train loss:0.11818862388601467\n",
      "train loss:0.1481927672402739\n",
      "train loss:0.12057850233058749\n",
      "train loss:0.06896336031803038\n",
      "train loss:0.14818827362897907\n",
      "train loss:0.14284751740801746\n",
      "train loss:0.05288535573210255\n",
      "train loss:0.17167039686252183\n",
      "train loss:0.0980099425648294\n",
      "train loss:0.05517438785471713\n",
      "train loss:0.032742328484535704\n",
      "train loss:0.08282896227294023\n",
      "train loss:0.028547212472674718\n",
      "train loss:0.07127147843664261\n",
      "train loss:0.16749086475408614\n",
      "train loss:0.055577385113947934\n",
      "train loss:0.09068876341131948\n",
      "train loss:0.036708670623171576\n",
      "train loss:0.12624390016099976\n",
      "train loss:0.12137949436312395\n",
      "train loss:0.046694202006198046\n",
      "train loss:0.04839689541576124\n",
      "train loss:0.09445424879530558\n",
      "train loss:0.03126048548157167\n",
      "train loss:0.09606054663986258\n",
      "train loss:0.14274281835153535\n",
      "train loss:0.15476674515121921\n",
      "train loss:0.10988126543344517\n",
      "train loss:0.14571351611010397\n",
      "train loss:0.07515502848732458\n",
      "train loss:0.15855752632004674\n",
      "train loss:0.1216165780038036\n",
      "train loss:0.105125578709365\n",
      "train loss:0.05692571669454444\n",
      "train loss:0.023657165463466762\n",
      "train loss:0.1628184290146257\n",
      "train loss:0.08889958150978117\n",
      "train loss:0.0729638197049379\n",
      "train loss:0.12908223954328402\n",
      "train loss:0.08421199106661781\n",
      "train loss:0.09367455581577604\n",
      "train loss:0.09921749602626022\n",
      "train loss:0.08310428468482499\n",
      "train loss:0.07478994110669844\n",
      "train loss:0.0890282831382763\n",
      "train loss:0.04696624657612064\n",
      "train loss:0.12713402242411445\n",
      "train loss:0.06853436027570883\n",
      "train loss:0.09207037843423294\n",
      "train loss:0.06471852896229292\n",
      "train loss:0.05350804343810744\n",
      "train loss:0.05953925336377784\n",
      "train loss:0.07400175388549701\n",
      "train loss:0.058269346267028045\n",
      "train loss:0.02807616094648665\n",
      "train loss:0.08208038887707561\n",
      "train loss:0.15123065363641738\n",
      "train loss:0.07152203115500635\n",
      "train loss:0.19436206678938095\n",
      "train loss:0.13686142368754795\n",
      "train loss:0.23839334061011047\n",
      "train loss:0.07409158021230203\n",
      "train loss:0.09719528318308406\n",
      "train loss:0.08723510962251632\n",
      "train loss:0.031917895275088544\n",
      "train loss:0.0715675659814027\n",
      "train loss:0.10290577640777993\n",
      "train loss:0.09760360540634636\n",
      "train loss:0.08441699716635327\n",
      "train loss:0.054066103422008675\n",
      "train loss:0.0847249063537716\n",
      "train loss:0.11683461760432863\n",
      "train loss:0.05276470601854715\n",
      "train loss:0.09169527041978229\n",
      "train loss:0.19267105296430434\n",
      "train loss:0.07487357348448026\n",
      "train loss:0.054386573723357305\n",
      "train loss:0.11231509216982775\n",
      "train loss:0.04212749568248811\n",
      "train loss:0.162635458869226\n",
      "train loss:0.10341425755890028\n",
      "train loss:0.08564727475033009\n",
      "train loss:0.04758892397652538\n",
      "train loss:0.044353420623120414\n",
      "train loss:0.06327692393339202\n",
      "train loss:0.06457808609734939\n",
      "train loss:0.12848390893852385\n",
      "train loss:0.07107374662626084\n",
      "train loss:0.10496224646407461\n",
      "train loss:0.0527358462851926\n",
      "train loss:0.09205749006258487\n",
      "train loss:0.10808077415697025\n",
      "train loss:0.06903535168325803\n",
      "train loss:0.06786355251688163\n",
      "train loss:0.07566150356354155\n",
      "train loss:0.0861766236376212\n",
      "train loss:0.16405922478586754\n",
      "train loss:0.07335888049219595\n",
      "train loss:0.033977678262543345\n",
      "train loss:0.07996867441753777\n",
      "train loss:0.08492778192846169\n",
      "train loss:0.10037230478068049\n",
      "train loss:0.06844936415720644\n",
      "train loss:0.0705805271721136\n",
      "train loss:0.04779384339206813\n",
      "train loss:0.07305716323614511\n",
      "train loss:0.018250573081240687\n",
      "train loss:0.10943473492551564\n",
      "train loss:0.0413613208150937\n",
      "train loss:0.08588501993111045\n",
      "train loss:0.02436600502580412\n",
      "train loss:0.07211539140292383\n",
      "train loss:0.06938902526507663\n",
      "train loss:0.10517396307129427\n",
      "train loss:0.05607596437070196\n",
      "train loss:0.0921063648278246\n",
      "train loss:0.23994149916928298\n",
      "train loss:0.046861218540825644\n",
      "train loss:0.026242472571438916\n",
      "train loss:0.13737297539472207\n",
      "train loss:0.06501075999786562\n",
      "train loss:0.0709893446061351\n",
      "train loss:0.06718077556778242\n",
      "train loss:0.08345979737197595\n",
      "train loss:0.09207571726160628\n",
      "train loss:0.056690613650296956\n",
      "train loss:0.025787697577041815\n",
      "train loss:0.04937717025339614\n",
      "train loss:0.059821418133228964\n",
      "train loss:0.06404858735189967\n",
      "train loss:0.0715851016642415\n",
      "train loss:0.11840148726836146\n",
      "train loss:0.05119308148995747\n",
      "train loss:0.0651745625869087\n",
      "train loss:0.04397101521662854\n",
      "train loss:0.06308934198983014\n",
      "train loss:0.036445954163118924\n",
      "train loss:0.1090960550146058\n",
      "train loss:0.04093917819351697\n",
      "train loss:0.08115727621265456\n",
      "train loss:0.10457395556025886\n",
      "train loss:0.12307190321369432\n",
      "train loss:0.11019254334835712\n",
      "train loss:0.07747316024522527\n",
      "train loss:0.11241441278800596\n",
      "train loss:0.03921292349234104\n",
      "train loss:0.049369588036434396\n",
      "train loss:0.13417548077538258\n",
      "train loss:0.07377034885607225\n",
      "train loss:0.09195254179851099\n",
      "train loss:0.10043116514835038\n",
      "train loss:0.06437655026095529\n",
      "train loss:0.0774020039398742\n",
      "train loss:0.06217927942191866\n",
      "train loss:0.04077698715397534\n",
      "train loss:0.07048149476824382\n",
      "train loss:0.12006942344500589\n",
      "train loss:0.025939592776940287\n",
      "train loss:0.07742966692274734\n",
      "train loss:0.06037741308613583\n",
      "train loss:0.10341186364258319\n",
      "train loss:0.0930221544049935\n",
      "train loss:0.15630346379103005\n",
      "train loss:0.05452394234770346\n",
      "train loss:0.03720229525153417\n",
      "train loss:0.0761359196832818\n",
      "train loss:0.06556849843875617\n",
      "train loss:0.05274137874561705\n",
      "train loss:0.25373479846516855\n",
      "train loss:0.09020860366331913\n",
      "train loss:0.05814535652849535\n",
      "train loss:0.19754330307715867\n",
      "train loss:0.0878828492429313\n",
      "train loss:0.09066626716836013\n",
      "train loss:0.023007861679290555\n",
      "train loss:0.020107440629444945\n",
      "train loss:0.1102495347243329\n",
      "train loss:0.03970463595406793\n",
      "train loss:0.05851135038877982\n",
      "train loss:0.05304587978043229\n",
      "train loss:0.11710737715156373\n",
      "train loss:0.05124238292834942\n",
      "train loss:0.04092863867706706\n",
      "train loss:0.06956540596988685\n",
      "train loss:0.1130846156156983\n",
      "train loss:0.06465609237107317\n",
      "train loss:0.18819580677423528\n",
      "train loss:0.07556779753194849\n",
      "train loss:0.11304757268316186\n",
      "train loss:0.13278382654950474\n",
      "train loss:0.045848376265663245\n",
      "train loss:0.05102104079301188\n",
      "train loss:0.1340367909148461\n",
      "train loss:0.14645614892730197\n",
      "train loss:0.028615230123807574\n",
      "train loss:0.16237232334073481\n",
      "train loss:0.037627212919936814\n",
      "train loss:0.07782886846607014\n",
      "train loss:0.16257488390838343\n",
      "train loss:0.09436446912827419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.02038666878895385\n",
      "train loss:0.01754327282555167\n",
      "train loss:0.059383240389229514\n",
      "train loss:0.05496099720764811\n",
      "train loss:0.12004462566280968\n",
      "train loss:0.043591275203694116\n",
      "train loss:0.03583168391799873\n",
      "train loss:0.05272360027371364\n",
      "train loss:0.05316580217853076\n",
      "train loss:0.08532054323110354\n",
      "train loss:0.020787389152921665\n",
      "train loss:0.053601573588076594\n",
      "train loss:0.11906867629991495\n",
      "train loss:0.06841455796894681\n",
      "train loss:0.030648266091858875\n",
      "train loss:0.04794238180803005\n",
      "train loss:0.04171834546843534\n",
      "train loss:0.044794223283569544\n",
      "train loss:0.03448613262383471\n",
      "train loss:0.08955363030973444\n",
      "train loss:0.01729450181662303\n",
      "train loss:0.09282035429703382\n",
      "train loss:0.03936877145415904\n",
      "train loss:0.028470957028288363\n",
      "train loss:0.032477580011757906\n",
      "train loss:0.016569307239856296\n",
      "train loss:0.03235968375483252\n",
      "train loss:0.04107369426091889\n",
      "train loss:0.0745156093954343\n",
      "train loss:0.04973375635499657\n",
      "train loss:0.11581668119937578\n",
      "train loss:0.07451329051286486\n",
      "train loss:0.07878984118138871\n",
      "train loss:0.045983196982697726\n",
      "train loss:0.01576124291296784\n",
      "train loss:0.015584375390979368\n",
      "train loss:0.12172607216726238\n",
      "train loss:0.047152044846741195\n",
      "train loss:0.14829467143734731\n",
      "train loss:0.11892872779656483\n",
      "train loss:0.07559645014122411\n",
      "train loss:0.0740450746895788\n",
      "train loss:0.14427077232487587\n",
      "train loss:0.05768171257363585\n",
      "train loss:0.07512422587366595\n",
      "train loss:0.07360047156540976\n",
      "train loss:0.10455086531944627\n",
      "train loss:0.038764633572049456\n",
      "train loss:0.1240124157701924\n",
      "train loss:0.05868996123071676\n",
      "train loss:0.023041393227049758\n",
      "train loss:0.02525222616740734\n",
      "train loss:0.05654838771761171\n",
      "train loss:0.08172243427034263\n",
      "train loss:0.05949584106138858\n",
      "train loss:0.027566212254722444\n",
      "train loss:0.050623584825812945\n",
      "train loss:0.043213489892724076\n",
      "train loss:0.027252665407318917\n",
      "train loss:0.10673278435286884\n",
      "train loss:0.0983616925762914\n",
      "train loss:0.08593530824468315\n",
      "train loss:0.06024932836918612\n",
      "train loss:0.12408457829041021\n",
      "train loss:0.051091533396117744\n",
      "train loss:0.1131909458485283\n",
      "train loss:0.04492510904081144\n",
      "train loss:0.13464001193663272\n",
      "train loss:0.03517631179324237\n",
      "train loss:0.06748838489483958\n",
      "train loss:0.06482716250079058\n",
      "train loss:0.07418667571376965\n",
      "train loss:0.05573335540531899\n",
      "train loss:0.03147079799670704\n",
      "train loss:0.06153468984521089\n",
      "train loss:0.08908439948739101\n",
      "train loss:0.0770576066349823\n",
      "train loss:0.07640029873022464\n",
      "train loss:0.1086841583079779\n",
      "train loss:0.1153598154539831\n",
      "train loss:0.03443372251658361\n",
      "train loss:0.214522533132605\n",
      "train loss:0.04359374497891161\n",
      "train loss:0.04529526534343344\n",
      "train loss:0.06604942362903181\n",
      "train loss:0.09415901089848905\n",
      "train loss:0.05681660982678512\n",
      "train loss:0.06022141979258259\n",
      "train loss:0.06413226327581864\n",
      "train loss:0.112147964020831\n",
      "train loss:0.06056849971178579\n",
      "train loss:0.02968202017213914\n",
      "train loss:0.037110995974879823\n",
      "train loss:0.15737084192032835\n",
      "train loss:0.02825362664460427\n",
      "train loss:0.15348998648167864\n",
      "train loss:0.043380021997165334\n",
      "train loss:0.12621153514909475\n",
      "train loss:0.12282828980345945\n",
      "train loss:0.026540425489462824\n",
      "train loss:0.05677280029489252\n",
      "train loss:0.10458086378114988\n",
      "train loss:0.042813333303381\n",
      "train loss:0.031049607692397837\n",
      "train loss:0.05084044885303375\n",
      "train loss:0.14099834658525606\n",
      "train loss:0.053455853259395614\n",
      "train loss:0.050449190152335684\n",
      "train loss:0.086066603868745\n",
      "train loss:0.09915439451060751\n",
      "train loss:0.054115704370038875\n",
      "train loss:0.10525039745318222\n",
      "train loss:0.05986734075680701\n",
      "train loss:0.048008752328870676\n",
      "train loss:0.07535125398575727\n",
      "train loss:0.13090320524673704\n",
      "train loss:0.06918866687117864\n",
      "train loss:0.03388477251381822\n",
      "train loss:0.14501199401669443\n",
      "train loss:0.0829671257877827\n",
      "train loss:0.07377202198276601\n",
      "train loss:0.08515925024948336\n",
      "train loss:0.09054853280147532\n",
      "train loss:0.13074975933819966\n",
      "train loss:0.08503875413191662\n",
      "train loss:0.045491719330779695\n",
      "train loss:0.04657647207720216\n",
      "train loss:0.05526066304209915\n",
      "train loss:0.052888902977907694\n",
      "train loss:0.07947140942928005\n",
      "train loss:0.07183500272080835\n",
      "train loss:0.10000830436661358\n",
      "train loss:0.04744839526863708\n",
      "train loss:0.10157643845717303\n",
      "=== epoch:3, train acc:0.98, test acc:0.976 ===\n",
      "train loss:0.07450004722723337\n",
      "train loss:0.0968905294855318\n",
      "train loss:0.08822803907333063\n",
      "train loss:0.06557033823717497\n",
      "train loss:0.07006263838569567\n",
      "train loss:0.04895540160040495\n",
      "train loss:0.07469812229856929\n",
      "train loss:0.04626489835906165\n",
      "train loss:0.095538780963626\n",
      "train loss:0.05814312425918481\n",
      "train loss:0.05665122315880258\n",
      "train loss:0.07154536748419038\n",
      "train loss:0.12393668818769427\n",
      "train loss:0.022742012421647275\n",
      "train loss:0.04784070646276413\n",
      "train loss:0.08951688506444824\n",
      "train loss:0.041792643257505036\n",
      "train loss:0.06479824443681044\n",
      "train loss:0.056311018569571984\n",
      "train loss:0.03435893490683262\n",
      "train loss:0.02005807388869824\n",
      "train loss:0.11136198069190796\n",
      "train loss:0.047565050608446464\n",
      "train loss:0.14017550980498264\n",
      "train loss:0.05704837264159075\n",
      "train loss:0.061752147845376006\n",
      "train loss:0.06488596208157507\n",
      "train loss:0.030793890535713825\n",
      "train loss:0.04268837513451531\n",
      "train loss:0.06009587928618926\n",
      "train loss:0.08316335978964613\n",
      "train loss:0.04028967751271994\n",
      "train loss:0.05465568400935819\n",
      "train loss:0.024671105197806072\n",
      "train loss:0.03201840516548045\n",
      "train loss:0.059009805014312154\n",
      "train loss:0.06350919658611956\n",
      "train loss:0.03139429820200015\n",
      "train loss:0.2656372884940506\n",
      "train loss:0.07646865453182493\n",
      "train loss:0.14397748992719486\n",
      "train loss:0.10408549866590042\n",
      "train loss:0.14143151408729449\n",
      "train loss:0.07291594520289169\n",
      "train loss:0.03645998768313439\n",
      "train loss:0.0580665072400621\n",
      "train loss:0.06930583993176806\n",
      "train loss:0.03907871280151704\n",
      "train loss:0.07858290797346995\n",
      "train loss:0.03472149461278001\n",
      "train loss:0.09295933721685921\n",
      "train loss:0.07187962321857964\n",
      "train loss:0.09363287994176937\n",
      "train loss:0.10460430230925807\n",
      "train loss:0.03856528862547452\n",
      "train loss:0.07841436171836727\n",
      "train loss:0.07917272387860314\n",
      "train loss:0.048683935434560795\n",
      "train loss:0.06629792637492658\n",
      "train loss:0.14512010581575738\n",
      "train loss:0.04614459463553509\n",
      "train loss:0.16513148533871255\n",
      "train loss:0.022531434725119183\n",
      "train loss:0.03333089767136349\n",
      "train loss:0.064564236014169\n",
      "train loss:0.035745858193890354\n",
      "train loss:0.06938170832367094\n",
      "train loss:0.08259961374229827\n",
      "train loss:0.03350738101468145\n",
      "train loss:0.052716705123858336\n",
      "train loss:0.06660063229255254\n",
      "train loss:0.10671165105420438\n",
      "train loss:0.03505180195831361\n",
      "train loss:0.060268477410958685\n",
      "train loss:0.03767473456806654\n",
      "train loss:0.08391886135514719\n",
      "train loss:0.028949065918825498\n",
      "train loss:0.20728145031815212\n",
      "train loss:0.04111904675275821\n",
      "train loss:0.0682045955719572\n",
      "train loss:0.042262436621084885\n",
      "train loss:0.04663521737806191\n",
      "train loss:0.05414453393372707\n",
      "train loss:0.13624286979624955\n",
      "train loss:0.020925549989475156\n",
      "train loss:0.04529061644611283\n",
      "train loss:0.06363774133558739\n",
      "train loss:0.010458448231701339\n",
      "train loss:0.037039499436839166\n",
      "train loss:0.2008744290909058\n",
      "train loss:0.04524065751976303\n",
      "train loss:0.06568702875853517\n",
      "train loss:0.02273491122844751\n",
      "train loss:0.08822081982923201\n",
      "train loss:0.08321858579397182\n",
      "train loss:0.046635579219007205\n",
      "train loss:0.1452329189738511\n",
      "train loss:0.0738188468088334\n",
      "train loss:0.08971307958613157\n",
      "train loss:0.04394303614778286\n",
      "train loss:0.02141384100607853\n",
      "train loss:0.04214952756667291\n",
      "train loss:0.050657768209087496\n",
      "train loss:0.0462709675228274\n",
      "train loss:0.11346119512438328\n",
      "train loss:0.03924311225413098\n",
      "train loss:0.11181449442138038\n",
      "train loss:0.051295038463645554\n",
      "train loss:0.050726543734906135\n",
      "train loss:0.03941806303736294\n",
      "train loss:0.11333902961394639\n",
      "train loss:0.06358405576724832\n",
      "train loss:0.06295968285564298\n",
      "train loss:0.043109008219514175\n",
      "train loss:0.08128729967212406\n",
      "train loss:0.0390145678520943\n",
      "train loss:0.044626948614859996\n",
      "train loss:0.036792008855129656\n",
      "train loss:0.06634605649250203\n",
      "train loss:0.15322569284421406\n",
      "train loss:0.01991123225261462\n",
      "train loss:0.1169209460753671\n",
      "train loss:0.03280971468236801\n",
      "train loss:0.08672800572641362\n",
      "train loss:0.10795093667252548\n",
      "train loss:0.02747116755038009\n",
      "train loss:0.04066994379494257\n",
      "train loss:0.08118236678087967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.03212432068378678\n",
      "train loss:0.06125259196919215\n",
      "train loss:0.0958477438465856\n",
      "train loss:0.16653077460038224\n",
      "train loss:0.020769567242877304\n",
      "train loss:0.06470125633230708\n",
      "train loss:0.047866831504633306\n",
      "train loss:0.03268066492925911\n",
      "train loss:0.047083865316658556\n",
      "train loss:0.06175112329259843\n",
      "train loss:0.030815408062763252\n",
      "train loss:0.04052404502449506\n",
      "train loss:0.07238209857590855\n",
      "train loss:0.03974728286035574\n",
      "train loss:0.051663336652195184\n",
      "train loss:0.09406517854665113\n",
      "train loss:0.0299231866018779\n",
      "train loss:0.042378062334220486\n",
      "train loss:0.013077069192261244\n",
      "train loss:0.11901472270621673\n",
      "train loss:0.024725590007127124\n",
      "train loss:0.04799077647327715\n",
      "train loss:0.0881184963697668\n",
      "train loss:0.08937970868431487\n",
      "train loss:0.04607742600993121\n",
      "train loss:0.14098330613835075\n",
      "train loss:0.042784594975631134\n",
      "train loss:0.08696303186660302\n",
      "train loss:0.05358718586142142\n",
      "train loss:0.0337993741884356\n",
      "train loss:0.038720270325387766\n",
      "train loss:0.043449327112245056\n",
      "train loss:0.06061300376425515\n",
      "train loss:0.018234285674839056\n",
      "train loss:0.04955088083070568\n",
      "train loss:0.03707363218422839\n",
      "train loss:0.02468923618142397\n",
      "train loss:0.08991785193538247\n",
      "train loss:0.01899720639379618\n",
      "train loss:0.040626436995034466\n",
      "train loss:0.12095650146764485\n",
      "train loss:0.06043309721871433\n",
      "train loss:0.046646402386262095\n",
      "train loss:0.060986975359445326\n",
      "train loss:0.03712096293960117\n",
      "train loss:0.056322246552327836\n",
      "train loss:0.02495484675192653\n",
      "train loss:0.15315939552427393\n",
      "train loss:0.1000587459214157\n",
      "train loss:0.06503893191455394\n",
      "train loss:0.03579914139246177\n",
      "train loss:0.12316308197903454\n",
      "train loss:0.020691990724957962\n",
      "train loss:0.11430999315810922\n",
      "train loss:0.06611175913419187\n",
      "train loss:0.06659357622317934\n",
      "train loss:0.09206483244993992\n",
      "train loss:0.04866890744534811\n",
      "train loss:0.14399206987582122\n",
      "train loss:0.020296592897613767\n",
      "train loss:0.05170385006010766\n",
      "train loss:0.04529007144137487\n",
      "train loss:0.03495232128648564\n",
      "train loss:0.11016179421353237\n",
      "train loss:0.04876823797319889\n",
      "train loss:0.15104404573266145\n",
      "train loss:0.0853040727541487\n",
      "train loss:0.04212460524547364\n",
      "train loss:0.03357097316860026\n",
      "train loss:0.027237682140480057\n",
      "train loss:0.17928708045967387\n",
      "train loss:0.08100791771667831\n",
      "train loss:0.11626375717054627\n",
      "train loss:0.05035750843673283\n",
      "train loss:0.08403004705899486\n",
      "train loss:0.08130371121264082\n",
      "train loss:0.08698907416627108\n",
      "train loss:0.12322999437760782\n",
      "train loss:0.05240305977802549\n",
      "train loss:0.01923851836087913\n",
      "train loss:0.029133653951965627\n",
      "train loss:0.06091377451945502\n",
      "train loss:0.0626100667723735\n",
      "train loss:0.1872338548747729\n",
      "train loss:0.07656650307195968\n",
      "train loss:0.05744678263001851\n",
      "train loss:0.06634235277035921\n",
      "train loss:0.0763544957000987\n",
      "train loss:0.07379603694804661\n",
      "train loss:0.010706135542139459\n",
      "train loss:0.0763874085595132\n",
      "train loss:0.048758777381902395\n",
      "train loss:0.03097487799112487\n",
      "train loss:0.04261631387144238\n",
      "train loss:0.1273962541139674\n",
      "train loss:0.07075833134945338\n",
      "train loss:0.04984065563429699\n",
      "train loss:0.02560832064225802\n",
      "train loss:0.07058473900417739\n",
      "train loss:0.046330419883653544\n",
      "train loss:0.03638231626968912\n",
      "train loss:0.023338663161863137\n",
      "train loss:0.046120549699357936\n",
      "train loss:0.08299011571442516\n",
      "train loss:0.036731807968027705\n",
      "train loss:0.08495890574568515\n",
      "train loss:0.09010724034483308\n",
      "train loss:0.023783727802396154\n",
      "train loss:0.0520565900127591\n",
      "train loss:0.045879074390382676\n",
      "train loss:0.05336277944358482\n",
      "train loss:0.030906070233130332\n",
      "train loss:0.017910397231715905\n",
      "train loss:0.14554205004075715\n",
      "train loss:0.05622861028246084\n",
      "train loss:0.047845618147969164\n",
      "train loss:0.06254004527739844\n",
      "train loss:0.08827851976727516\n",
      "train loss:0.08613784023645316\n",
      "train loss:0.02370991187414337\n",
      "train loss:0.13161950115689267\n",
      "train loss:0.035657394356716623\n",
      "train loss:0.10938868044135587\n",
      "train loss:0.02371494309745053\n",
      "train loss:0.08729049161963659\n",
      "train loss:0.049833016250363925\n",
      "train loss:0.10090476802281546\n",
      "train loss:0.1592665405295932\n",
      "train loss:0.06875143271518513\n",
      "train loss:0.049201000614857486\n",
      "train loss:0.10843312262306445\n",
      "train loss:0.03354418702794197\n",
      "train loss:0.04107459777071969\n",
      "train loss:0.04576387730068628\n",
      "train loss:0.07845725375891995\n",
      "train loss:0.08610833578039057\n",
      "train loss:0.12026522235060932\n",
      "train loss:0.04034293924930466\n",
      "train loss:0.032452211295064426\n",
      "train loss:0.11744255086236086\n",
      "train loss:0.16442478475724742\n",
      "train loss:0.01703544744759212\n",
      "train loss:0.051057343012578284\n",
      "train loss:0.09751895839611865\n",
      "train loss:0.06072923995973133\n",
      "train loss:0.05626014136275564\n",
      "train loss:0.04173783111961342\n",
      "train loss:0.030006470926585146\n",
      "train loss:0.013887069691246114\n",
      "train loss:0.04253010675764766\n",
      "train loss:0.04294410502119488\n",
      "train loss:0.06156007451658981\n",
      "train loss:0.07989592115173018\n",
      "train loss:0.03470153641016654\n",
      "train loss:0.1676735804931652\n",
      "train loss:0.03253449658860199\n",
      "train loss:0.02987921051040197\n",
      "train loss:0.0412274840805412\n",
      "train loss:0.1431372954469679\n",
      "train loss:0.11713991463560375\n",
      "train loss:0.022620842598251704\n",
      "train loss:0.024347603221830952\n",
      "train loss:0.03825906018909\n",
      "train loss:0.056077485119349256\n",
      "train loss:0.05225705847921579\n",
      "train loss:0.0891376605614138\n",
      "train loss:0.073974525274143\n",
      "train loss:0.04132258689101706\n",
      "train loss:0.09041727064354194\n",
      "train loss:0.02693481317876116\n",
      "train loss:0.015477175036126643\n",
      "train loss:0.11706767615416062\n",
      "train loss:0.021019550053296986\n",
      "train loss:0.020783206276997365\n",
      "train loss:0.08281647212087272\n",
      "train loss:0.02660235144586708\n",
      "train loss:0.018445112894331917\n",
      "train loss:0.029976904850198386\n",
      "train loss:0.016534958960593763\n",
      "train loss:0.05411045726089237\n",
      "train loss:0.03688877486267241\n",
      "train loss:0.01648940242392741\n",
      "train loss:0.1041197498667869\n",
      "train loss:0.08634559222257371\n",
      "train loss:0.10606065336356478\n",
      "train loss:0.026563168415582407\n",
      "train loss:0.06278676315878441\n",
      "train loss:0.02794465247057068\n",
      "train loss:0.053976154678271576\n",
      "train loss:0.037815685209502486\n",
      "train loss:0.026488079867880012\n",
      "train loss:0.06737389408527722\n",
      "train loss:0.032803165437369365\n",
      "train loss:0.041334790370920124\n",
      "train loss:0.07083014175655732\n",
      "train loss:0.022540092161172226\n",
      "train loss:0.06184465136803694\n",
      "train loss:0.038147698928998615\n",
      "train loss:0.012640274488795677\n",
      "train loss:0.06967185118598251\n",
      "train loss:0.12792850191140023\n",
      "train loss:0.02698502423887704\n",
      "train loss:0.029179248690132477\n",
      "train loss:0.06450053980274874\n",
      "train loss:0.04533897945404677\n",
      "train loss:0.029280843831440587\n",
      "train loss:0.09345131985006129\n",
      "train loss:0.0428155990699858\n",
      "train loss:0.008689142059779787\n",
      "train loss:0.0153589584004756\n",
      "train loss:0.08206203381126183\n",
      "train loss:0.13348622208192726\n",
      "train loss:0.04155913272513745\n",
      "train loss:0.032271749253768856\n",
      "train loss:0.0960417181779933\n",
      "train loss:0.08829523921926245\n",
      "train loss:0.01837966772647591\n",
      "train loss:0.030965841966016202\n",
      "train loss:0.027145352557153536\n",
      "train loss:0.024949589371105127\n",
      "train loss:0.019844631498298626\n",
      "train loss:0.13795290991445996\n",
      "train loss:0.044844597559191596\n",
      "train loss:0.06783593694520575\n",
      "train loss:0.0352214019968696\n",
      "train loss:0.0571569770728212\n",
      "train loss:0.01577099952601169\n",
      "train loss:0.06878289719608834\n",
      "train loss:0.04823099204525425\n",
      "train loss:0.08389723729002112\n",
      "train loss:0.06802053662816196\n",
      "train loss:0.09966824474622404\n",
      "train loss:0.10999349394575722\n",
      "train loss:0.07141845152810515\n",
      "train loss:0.11628477546478522\n",
      "train loss:0.026349254173437614\n",
      "train loss:0.09356132261003586\n",
      "train loss:0.05062656369576856\n",
      "train loss:0.1323528529870587\n",
      "train loss:0.10820721738964649\n",
      "train loss:0.09695432144564897\n",
      "train loss:0.0321638880487964\n",
      "train loss:0.03144663955198637\n",
      "train loss:0.10748345323206904\n",
      "train loss:0.039767785304590776\n",
      "train loss:0.20508026853628528\n",
      "train loss:0.11517695633919336\n",
      "train loss:0.04589138081951385\n",
      "train loss:0.050390747556122634\n",
      "train loss:0.0171063022262421\n",
      "train loss:0.047832993738872905\n",
      "train loss:0.07622449882301897\n",
      "train loss:0.043995132056447436\n",
      "train loss:0.030329380729101435\n",
      "train loss:0.05742260222098264\n",
      "train loss:0.05438389937844712\n",
      "train loss:0.04517026967262286\n",
      "train loss:0.035012374860903535\n",
      "train loss:0.043986995731815456\n",
      "train loss:0.07670493950181786\n",
      "train loss:0.027493444808287738\n",
      "train loss:0.038462132048218974\n",
      "train loss:0.02551379391959041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.018094771456227687\n",
      "train loss:0.06533727653758542\n",
      "train loss:0.03521318731907829\n",
      "train loss:0.07632043007513074\n",
      "train loss:0.07727619462256546\n",
      "train loss:0.013092578902373711\n",
      "train loss:0.03398258702978332\n",
      "train loss:0.0339793748602913\n",
      "train loss:0.037898477285286586\n",
      "train loss:0.02959934756709029\n",
      "train loss:0.08423906015010309\n",
      "train loss:0.06237102530760045\n",
      "train loss:0.036277526082878875\n",
      "train loss:0.037885340587818755\n",
      "train loss:0.029511935681212343\n",
      "train loss:0.06352862532088192\n",
      "train loss:0.11396116899857052\n",
      "train loss:0.029278029558130473\n",
      "train loss:0.07662011395442657\n",
      "train loss:0.0484231880026715\n",
      "train loss:0.024628710991642253\n",
      "train loss:0.022060643890443182\n",
      "train loss:0.059120809022192494\n",
      "train loss:0.03856266796505404\n",
      "train loss:0.12686594363077425\n",
      "train loss:0.05132409519145503\n",
      "train loss:0.09354297460705631\n",
      "train loss:0.046838020185880076\n",
      "train loss:0.04500672067531435\n",
      "train loss:0.035249332116937905\n",
      "train loss:0.03557899330089892\n",
      "train loss:0.03933775953192689\n",
      "train loss:0.02094712119124788\n",
      "train loss:0.009547441580070428\n",
      "train loss:0.03852022118035613\n",
      "train loss:0.1541741664409983\n",
      "train loss:0.03247049537459935\n",
      "train loss:0.07380709285670686\n",
      "train loss:0.07831094360805374\n",
      "train loss:0.05538131948207004\n",
      "train loss:0.1127101809870321\n",
      "train loss:0.01708227463440513\n",
      "train loss:0.07799837384968568\n",
      "train loss:0.09768768282438459\n",
      "train loss:0.07775949249842108\n",
      "train loss:0.06002290658812712\n",
      "train loss:0.08067732565188244\n",
      "train loss:0.014452112329911417\n",
      "train loss:0.05846887452119944\n",
      "train loss:0.07338711991189245\n",
      "train loss:0.12202055879245596\n",
      "train loss:0.1123458832105391\n",
      "train loss:0.031605089137958245\n",
      "train loss:0.08007967281969225\n",
      "train loss:0.03412758801965437\n",
      "train loss:0.02703060335881216\n",
      "train loss:0.09352720023817268\n",
      "train loss:0.08802761004408068\n",
      "train loss:0.04079171346173923\n",
      "train loss:0.051088658455922954\n",
      "train loss:0.02986441335730588\n",
      "train loss:0.06982979452645682\n",
      "train loss:0.04722698208862563\n",
      "train loss:0.04548162381767178\n",
      "train loss:0.021628602756989933\n",
      "train loss:0.05508169621490795\n",
      "train loss:0.0694001070397457\n",
      "train loss:0.06336327390010446\n",
      "train loss:0.1060722146210829\n",
      "train loss:0.049824087968117076\n",
      "train loss:0.0509339448013242\n",
      "train loss:0.06307942142612216\n",
      "train loss:0.016607738437138482\n",
      "train loss:0.029303875622237508\n",
      "train loss:0.05927821043620675\n",
      "train loss:0.058723075578473526\n",
      "train loss:0.017165018676972094\n",
      "train loss:0.04154069519020538\n",
      "train loss:0.08186331282772125\n",
      "train loss:0.040894172426709625\n",
      "train loss:0.05692647287926014\n",
      "train loss:0.0823792472504144\n",
      "train loss:0.04979728923691617\n",
      "train loss:0.05843717896677553\n",
      "train loss:0.10528674109408849\n",
      "train loss:0.044675268758876896\n",
      "train loss:0.01566704628034622\n",
      "train loss:0.03905030993634932\n",
      "train loss:0.030931406154926178\n",
      "train loss:0.052345299942667366\n",
      "train loss:0.04753995668302172\n",
      "train loss:0.04060056846573922\n",
      "train loss:0.03618833121166488\n",
      "train loss:0.05112481079189454\n",
      "train loss:0.009742292031751643\n",
      "train loss:0.14589914003607413\n",
      "train loss:0.044560229517586605\n",
      "train loss:0.07754594610404\n",
      "train loss:0.11687369336805693\n",
      "train loss:0.01731275753596602\n",
      "train loss:0.04312702587847874\n",
      "train loss:0.12050470619833822\n",
      "train loss:0.07978855117612586\n",
      "train loss:0.020110327922099033\n",
      "train loss:0.01719205150737433\n",
      "train loss:0.18935381723067204\n",
      "train loss:0.03801466016269945\n",
      "train loss:0.024782220047880454\n",
      "train loss:0.03134187300595588\n",
      "train loss:0.031006289592207584\n",
      "train loss:0.0394933813857405\n",
      "train loss:0.08199644592116954\n",
      "train loss:0.10590061530946597\n",
      "train loss:0.029202040977552853\n",
      "train loss:0.12088830316690395\n",
      "train loss:0.035905558111682764\n",
      "train loss:0.0404138404897594\n",
      "train loss:0.031435079251920676\n",
      "train loss:0.01979179849744074\n",
      "train loss:0.015599357921407032\n",
      "train loss:0.04658159927532681\n",
      "train loss:0.077642998999023\n",
      "train loss:0.03465688446613844\n",
      "train loss:0.018367864672242492\n",
      "train loss:0.09889854722852283\n",
      "train loss:0.11705915222858687\n",
      "train loss:0.02966896534692852\n",
      "train loss:0.1189116063448436\n",
      "train loss:0.03758562433438319\n",
      "train loss:0.0742806447139155\n",
      "train loss:0.019073770400147527\n",
      "train loss:0.08494363835987255\n",
      "train loss:0.046793980033059596\n",
      "train loss:0.021106471366745976\n",
      "train loss:0.03753300366406255\n",
      "train loss:0.03213765290352497\n",
      "train loss:0.13663424279555086\n",
      "train loss:0.01411175386935567\n",
      "train loss:0.0499156861758533\n",
      "train loss:0.18145673771523507\n",
      "train loss:0.09934900539931611\n",
      "train loss:0.037786083417291345\n",
      "train loss:0.0341913165425626\n",
      "train loss:0.019303083759975345\n",
      "train loss:0.06732805054165493\n",
      "train loss:0.05265956312473957\n",
      "train loss:0.08732054782845332\n",
      "train loss:0.07643196346151707\n",
      "train loss:0.07602780128294573\n",
      "train loss:0.03960340149179168\n",
      "train loss:0.03942801773035601\n",
      "train loss:0.024101614257935302\n",
      "train loss:0.03873595300288014\n",
      "train loss:0.10994052029585999\n",
      "train loss:0.11971321395534262\n",
      "train loss:0.06594498134631127\n",
      "train loss:0.06135136201341807\n",
      "train loss:0.009616404183817807\n",
      "train loss:0.04001208425500788\n",
      "train loss:0.16659787589319117\n",
      "train loss:0.03313966104086259\n",
      "train loss:0.08737126256408895\n",
      "train loss:0.014942252111049268\n",
      "train loss:0.030174250592275614\n",
      "train loss:0.07333870885583858\n",
      "train loss:0.07144288986791678\n",
      "train loss:0.0700187597025527\n",
      "train loss:0.05736572275540114\n",
      "train loss:0.049014164929913055\n",
      "train loss:0.05329026177035521\n",
      "train loss:0.049287314747523646\n",
      "train loss:0.05634969596289225\n",
      "train loss:0.024619382621250532\n",
      "train loss:0.04057913978471318\n",
      "train loss:0.0682531000656759\n",
      "train loss:0.013917770166162309\n",
      "train loss:0.05514999574156911\n",
      "train loss:0.018876556567391848\n",
      "train loss:0.1038109987532273\n",
      "train loss:0.03479605693206559\n",
      "train loss:0.014060989209069475\n",
      "train loss:0.07462603780060699\n",
      "train loss:0.04544640433834651\n",
      "train loss:0.03035920312789274\n",
      "train loss:0.04862964715003248\n",
      "train loss:0.06592488781842903\n",
      "train loss:0.015140650900599361\n",
      "train loss:0.02747773755237886\n",
      "train loss:0.14522686197074833\n",
      "train loss:0.015691271866511817\n",
      "train loss:0.10040064866795033\n",
      "train loss:0.02156318660982613\n",
      "train loss:0.05785241954075736\n",
      "train loss:0.10867875092627342\n",
      "train loss:0.05467380385684467\n",
      "train loss:0.0280697165886086\n",
      "train loss:0.0364812077994563\n",
      "train loss:0.05518836078603793\n",
      "train loss:0.009639008853359787\n",
      "train loss:0.09298585615131262\n",
      "train loss:0.02050163064744205\n",
      "train loss:0.04303803365053253\n",
      "train loss:0.01770305997703892\n",
      "train loss:0.058182241269284576\n",
      "train loss:0.08327049160620138\n",
      "train loss:0.02753394042300034\n",
      "train loss:0.03620133788062689\n",
      "train loss:0.017554186047445217\n",
      "train loss:0.04708230604593748\n",
      "=== epoch:4, train acc:0.983, test acc:0.98 ===\n",
      "train loss:0.011096012184361315\n",
      "train loss:0.009021021164853376\n",
      "train loss:0.03259118531029699\n",
      "train loss:0.024170852482719166\n",
      "train loss:0.02139399143719355\n",
      "train loss:0.05567509903080031\n",
      "train loss:0.09412583626750816\n",
      "train loss:0.06495556287097942\n",
      "train loss:0.07580405982993281\n",
      "train loss:0.015595104799798193\n",
      "train loss:0.1232087901916306\n",
      "train loss:0.0966320993181346\n",
      "train loss:0.02949749951110888\n",
      "train loss:0.05218940733600954\n",
      "train loss:0.06478441747794078\n",
      "train loss:0.06402536317892359\n",
      "train loss:0.0674849886480116\n",
      "train loss:0.020069806964325795\n",
      "train loss:0.06564641452282272\n",
      "train loss:0.03049133279870597\n",
      "train loss:0.08449335721706724\n",
      "train loss:0.04995574616383688\n",
      "train loss:0.02100913760430011\n",
      "train loss:0.04249214459361477\n",
      "train loss:0.06058043685100932\n",
      "train loss:0.18744167453370633\n",
      "train loss:0.04251144412456302\n",
      "train loss:0.08022899310954439\n",
      "train loss:0.034078395623016185\n",
      "train loss:0.03429256566203522\n",
      "train loss:0.09534972589855686\n",
      "train loss:0.056271701450705376\n",
      "train loss:0.05389384940180452\n",
      "train loss:0.0407230309199461\n",
      "train loss:0.05040291546684151\n",
      "train loss:0.026357218794538076\n",
      "train loss:0.019904898751061405\n",
      "train loss:0.04235630164294837\n",
      "train loss:0.025478598058567593\n",
      "train loss:0.09359377718016706\n",
      "train loss:0.023737974706630024\n",
      "train loss:0.07537237063522839\n",
      "train loss:0.04363533253791838\n",
      "train loss:0.03412100435713417\n",
      "train loss:0.061636358842580785\n",
      "train loss:0.025272453259724256\n",
      "train loss:0.05064231330157726\n",
      "train loss:0.015238711220749657\n",
      "train loss:0.040754262721703426\n",
      "train loss:0.04618216970829534\n",
      "train loss:0.04053811127762974\n",
      "train loss:0.073082245850746\n",
      "train loss:0.06964963492842778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.03783000049549166\n",
      "train loss:0.0296866193477548\n",
      "train loss:0.09899234687593599\n",
      "train loss:0.048696453779831346\n",
      "train loss:0.03956736128367611\n",
      "train loss:0.027579733452716932\n",
      "train loss:0.03410116947842431\n",
      "train loss:0.08174138526225837\n",
      "train loss:0.05704477279874202\n",
      "train loss:0.03494598317260058\n",
      "train loss:0.07600075262002268\n",
      "train loss:0.06560845588433026\n",
      "train loss:0.019946808541643938\n",
      "train loss:0.07054094122903214\n",
      "train loss:0.01053229702415612\n",
      "train loss:0.08465075959403358\n",
      "train loss:0.10519054852481659\n",
      "train loss:0.04620103126921862\n",
      "train loss:0.03627931871383817\n",
      "train loss:0.007807203135849058\n",
      "train loss:0.011349984957420511\n",
      "train loss:0.06583475656485428\n",
      "train loss:0.042086131383688746\n",
      "train loss:0.04756879424732986\n",
      "train loss:0.020616761597697028\n",
      "train loss:0.06192408986158841\n",
      "train loss:0.06641797574584413\n",
      "train loss:0.038859961430358456\n",
      "train loss:0.02515668445703796\n",
      "train loss:0.04495756929169263\n",
      "train loss:0.012716952924598424\n",
      "train loss:0.018660274867341328\n",
      "train loss:0.06636994282251253\n",
      "train loss:0.031883651951870845\n",
      "train loss:0.02819020024126427\n",
      "train loss:0.039797691935616046\n",
      "train loss:0.04696254402155406\n",
      "train loss:0.056686145947336966\n",
      "train loss:0.014445989608958362\n",
      "train loss:0.037387135271399\n",
      "train loss:0.0407483845721145\n",
      "train loss:0.03318007748637875\n",
      "train loss:0.09654745788879864\n",
      "train loss:0.03829926648078026\n",
      "train loss:0.007820849719710756\n",
      "train loss:0.01708569255177909\n",
      "train loss:0.06276866919167802\n",
      "train loss:0.012736762468249079\n",
      "train loss:0.08750339713461568\n",
      "train loss:0.00597383962349263\n",
      "train loss:0.012636728337688698\n",
      "train loss:0.05107471490295239\n",
      "train loss:0.05990662316431274\n",
      "train loss:0.0701133142757629\n",
      "train loss:0.030690200219184734\n",
      "train loss:0.08405624145524619\n",
      "train loss:0.05122946006563366\n",
      "train loss:0.09402211939158052\n",
      "train loss:0.026341233663697654\n",
      "train loss:0.009186039413527098\n",
      "train loss:0.020712752072519717\n",
      "train loss:0.027674017715509914\n",
      "train loss:0.07215165000510204\n",
      "train loss:0.028519507473665134\n",
      "train loss:0.022454781844786\n",
      "train loss:0.06013124480588874\n",
      "train loss:0.0485382257373387\n",
      "train loss:0.05480073112928767\n",
      "train loss:0.03405596380502983\n",
      "train loss:0.06702790163793551\n",
      "train loss:0.10354625235051312\n",
      "train loss:0.07587903793550434\n",
      "train loss:0.04088281923097125\n",
      "train loss:0.07893610068373888\n",
      "train loss:0.03341726845531463\n",
      "train loss:0.06007088872591271\n",
      "train loss:0.04004037865118075\n",
      "train loss:0.017853209059554082\n",
      "train loss:0.03470123226476992\n",
      "train loss:0.05413299101306345\n",
      "train loss:0.0856346399147781\n",
      "train loss:0.01966611423729336\n",
      "train loss:0.04784986118059348\n",
      "train loss:0.05191449939535328\n",
      "train loss:0.039538149286684574\n",
      "train loss:0.04269161307213409\n",
      "train loss:0.10625268505522147\n",
      "train loss:0.02338857896711966\n",
      "train loss:0.09073687190872932\n",
      "train loss:0.04195039740603583\n",
      "train loss:0.05693038719439085\n",
      "train loss:0.027544194481206215\n",
      "train loss:0.049587727582541145\n",
      "train loss:0.01573779597188575\n",
      "train loss:0.06641348131477388\n",
      "train loss:0.027238168649117118\n",
      "train loss:0.044127473020855304\n",
      "train loss:0.09394284968439198\n",
      "train loss:0.13017551378636955\n",
      "train loss:0.10230019631262975\n",
      "train loss:0.011538023083994191\n",
      "train loss:0.03985044226443485\n",
      "train loss:0.057022519166037566\n",
      "train loss:0.012834520536356968\n",
      "train loss:0.04332220487890044\n",
      "train loss:0.039313572230043156\n",
      "train loss:0.08271944577408898\n",
      "train loss:0.0942233745857524\n",
      "train loss:0.03679894958246884\n",
      "train loss:0.055106076623377874\n",
      "train loss:0.0801929156329821\n",
      "train loss:0.0752064538406751\n",
      "train loss:0.03274635006423368\n",
      "train loss:0.06851605861291969\n",
      "train loss:0.01570010647953806\n",
      "train loss:0.017428991276138284\n",
      "train loss:0.017635070039686184\n",
      "train loss:0.0528753295656726\n",
      "train loss:0.008658129447951891\n",
      "train loss:0.02572839350945825\n",
      "train loss:0.016161991051832997\n",
      "train loss:0.012409896270258538\n",
      "train loss:0.09105531260592072\n",
      "train loss:0.08432339858880493\n",
      "train loss:0.06573043332672811\n",
      "train loss:0.010079149735282986\n",
      "train loss:0.0471755220273653\n",
      "train loss:0.014468023506479575\n",
      "train loss:0.04355868126798319\n",
      "train loss:0.01809108808104913\n",
      "train loss:0.028670068199260344\n",
      "train loss:0.006861623850114806\n",
      "train loss:0.011386443103347339\n",
      "train loss:0.030935223019280582\n",
      "train loss:0.016692778127909483\n",
      "train loss:0.020062874640379858\n",
      "train loss:0.06258381902357783\n",
      "train loss:0.054660664423900565\n",
      "train loss:0.08848112689567424\n",
      "train loss:0.01103010715861245\n",
      "train loss:0.07043664798737384\n",
      "train loss:0.03938910531467841\n",
      "train loss:0.02410195045661431\n",
      "train loss:0.023353863408768695\n",
      "train loss:0.04507422645408665\n",
      "train loss:0.05235337652753094\n",
      "train loss:0.06014983579054541\n",
      "train loss:0.04020261109100329\n",
      "train loss:0.02207614227684873\n",
      "train loss:0.022078462716574706\n",
      "train loss:0.03759007919740014\n",
      "train loss:0.01799748829163329\n",
      "train loss:0.05199803375709149\n",
      "train loss:0.057779000647681586\n",
      "train loss:0.07204381490367137\n",
      "train loss:0.10530430604964963\n",
      "train loss:0.03206788635259325\n",
      "train loss:0.09100723891392942\n",
      "train loss:0.016954573141512542\n",
      "train loss:0.04438436170588374\n",
      "train loss:0.06244857016148746\n",
      "train loss:0.05009999136525198\n",
      "train loss:0.03482888881237803\n",
      "train loss:0.016782826637297722\n",
      "train loss:0.028006507906383402\n",
      "train loss:0.01726759883132952\n",
      "train loss:0.030096532111607517\n",
      "train loss:0.013896724231000817\n",
      "train loss:0.03308881206428236\n",
      "train loss:0.019773976527480065\n",
      "train loss:0.04556231941111459\n",
      "train loss:0.06695412654797187\n",
      "train loss:0.025853708942072583\n",
      "train loss:0.027569661841394703\n",
      "train loss:0.03696183575565832\n",
      "train loss:0.03885559499891204\n",
      "train loss:0.05281272285456822\n",
      "train loss:0.06903657711625315\n",
      "train loss:0.03414809576573443\n",
      "train loss:0.05576555988517159\n",
      "train loss:0.01624350139003137\n",
      "train loss:0.04466457142544932\n",
      "train loss:0.018534017257519516\n",
      "train loss:0.02559268950310749\n",
      "train loss:0.03333224936001604\n",
      "train loss:0.017283080715697785\n",
      "train loss:0.0533892128375474\n",
      "train loss:0.08356453001513196\n",
      "train loss:0.04388952955922651\n",
      "train loss:0.0231689748889328\n",
      "train loss:0.025298025118617878\n",
      "train loss:0.05961485465164901\n",
      "train loss:0.11997638752973108\n",
      "train loss:0.0525749820772813\n",
      "train loss:0.12170720912872335\n",
      "train loss:0.0611973234681046\n",
      "train loss:0.036285224765665376\n",
      "train loss:0.04461361332896588\n",
      "train loss:0.0735712149582708\n",
      "train loss:0.024853641652542443\n",
      "train loss:0.03912994010373961\n",
      "train loss:0.052305096848477645\n",
      "train loss:0.025049091099589943\n",
      "train loss:0.0313488787653214\n",
      "train loss:0.08601970032221028\n",
      "train loss:0.10864612885872728\n",
      "train loss:0.01926852168539217\n",
      "train loss:0.01028874287014643\n",
      "train loss:0.01660634957575258\n",
      "train loss:0.01051473060628201\n",
      "train loss:0.13695537264700186\n",
      "train loss:0.03040736718197854\n",
      "train loss:0.08847776860372275\n",
      "train loss:0.024720296329020952\n",
      "train loss:0.023218023025833506\n",
      "train loss:0.037124975709044265\n",
      "train loss:0.05545093156498988\n",
      "train loss:0.04466137979747967\n",
      "train loss:0.028207324186452432\n",
      "train loss:0.008897819824917635\n",
      "train loss:0.041979056903353414\n",
      "train loss:0.01711467923556255\n",
      "train loss:0.1189330752497201\n",
      "train loss:0.03970900798807848\n",
      "train loss:0.04886672487513885\n",
      "train loss:0.013759965824200884\n",
      "train loss:0.01626851051344359\n",
      "train loss:0.021286178206274403\n",
      "train loss:0.03132121204878017\n",
      "train loss:0.06970810348379221\n",
      "train loss:0.018965268758677517\n",
      "train loss:0.05537462844793699\n",
      "train loss:0.09370100404492376\n",
      "train loss:0.04186294411926114\n",
      "train loss:0.06326206759042483\n",
      "train loss:0.019127361615080028\n",
      "train loss:0.035233228264238824\n",
      "train loss:0.0590709844751654\n",
      "train loss:0.048596771515067465\n",
      "train loss:0.019521399149404584\n",
      "train loss:0.035990799789444784\n",
      "train loss:0.04569235139596404\n",
      "train loss:0.028808653183563463\n",
      "train loss:0.06239188723181816\n",
      "train loss:0.0320426503938261\n",
      "train loss:0.022664491003922985\n",
      "train loss:0.0753737527602713\n",
      "train loss:0.01023872720368998\n",
      "train loss:0.04625280060264413\n",
      "train loss:0.08063301215564815\n",
      "train loss:0.027257331647226657\n",
      "train loss:0.015406680687509779\n",
      "train loss:0.023923538494040105\n",
      "train loss:0.05175297826425175\n",
      "train loss:0.05029838208252627\n",
      "train loss:0.064018952462829\n",
      "train loss:0.03213917567669183\n",
      "train loss:0.04434670105063021\n",
      "train loss:0.01419030884095626\n",
      "train loss:0.012953363431004174\n",
      "train loss:0.03855408127496247\n",
      "train loss:0.026915824685154098\n",
      "train loss:0.12546045502052683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.06080194927963902\n",
      "train loss:0.054140532324021516\n",
      "train loss:0.05895718518212073\n",
      "train loss:0.06181196598171145\n",
      "train loss:0.04353663213354458\n",
      "train loss:0.02711462258903944\n",
      "train loss:0.03014468440149773\n",
      "train loss:0.04114644655123827\n",
      "train loss:0.0911656107224522\n",
      "train loss:0.016855679967749403\n",
      "train loss:0.02255017471334459\n",
      "train loss:0.06808213844282579\n",
      "train loss:0.028296438400383744\n",
      "train loss:0.028307197096351686\n",
      "train loss:0.030106053036097893\n",
      "train loss:0.057789022580145656\n",
      "train loss:0.020284445474406866\n",
      "train loss:0.13805243404664008\n",
      "train loss:0.007265146022470089\n",
      "train loss:0.05226853944547645\n",
      "train loss:0.047881600356165475\n",
      "train loss:0.0958853339527555\n",
      "train loss:0.009596676645827034\n",
      "train loss:0.055096976867800074\n",
      "train loss:0.015949027629184046\n",
      "train loss:0.019921488300026227\n",
      "train loss:0.025314562330706926\n",
      "train loss:0.031024927107824583\n",
      "train loss:0.028039961336450512\n",
      "train loss:0.01957938023231609\n",
      "train loss:0.08869012843930171\n",
      "train loss:0.05273951973540031\n",
      "train loss:0.00601693997219869\n",
      "train loss:0.05758324397056213\n",
      "train loss:0.023320125020885953\n",
      "train loss:0.011529493019021057\n",
      "train loss:0.054773457315569464\n",
      "train loss:0.045854351608249265\n",
      "train loss:0.018703137801184225\n",
      "train loss:0.03637695675325773\n",
      "train loss:0.011753380724024527\n",
      "train loss:0.0381648359694725\n",
      "train loss:0.046713575942677464\n",
      "train loss:0.038750166034505845\n",
      "train loss:0.06716697506109126\n",
      "train loss:0.011807526126936809\n",
      "train loss:0.06585824019284589\n",
      "train loss:0.04972397843265645\n",
      "train loss:0.015978094065584626\n",
      "train loss:0.007036730797061443\n",
      "train loss:0.02754748743477691\n",
      "train loss:0.04382625814956532\n",
      "train loss:0.020112345980396212\n",
      "train loss:0.03063605956131228\n",
      "train loss:0.021822796424505332\n",
      "train loss:0.0976203724793165\n",
      "train loss:0.014497590871745174\n",
      "train loss:0.00893623900467993\n",
      "train loss:0.05961370626392413\n",
      "train loss:0.04283824006257598\n",
      "train loss:0.02510016407051522\n",
      "train loss:0.03365979317430516\n",
      "train loss:0.08211866655889155\n",
      "train loss:0.015177165063443339\n",
      "train loss:0.008985691527899674\n",
      "train loss:0.02670520995826076\n",
      "train loss:0.016019220024915796\n",
      "train loss:0.03179559813083623\n",
      "train loss:0.04187839686844885\n",
      "train loss:0.03357866973561742\n",
      "train loss:0.029280396870938922\n",
      "train loss:0.04085415298795223\n",
      "train loss:0.02093727891509351\n",
      "train loss:0.023487756131884613\n",
      "train loss:0.015136797842485263\n",
      "train loss:0.04272331323032401\n",
      "train loss:0.058086979123614324\n",
      "train loss:0.07191245820421716\n",
      "train loss:0.025267248320044317\n",
      "train loss:0.050804329152681175\n",
      "train loss:0.05677251206068848\n",
      "train loss:0.19572863748242206\n",
      "train loss:0.02675631074399973\n",
      "train loss:0.015334565494754588\n",
      "train loss:0.03258853026168733\n",
      "train loss:0.04506220445379241\n",
      "train loss:0.05143628795878153\n",
      "train loss:0.023375443032792688\n",
      "train loss:0.07970895608013472\n",
      "train loss:0.015141578564645574\n",
      "train loss:0.04058468760343106\n",
      "train loss:0.07732232070055461\n",
      "train loss:0.017566759814598897\n",
      "train loss:0.10422344911490507\n",
      "train loss:0.07185999020050854\n",
      "train loss:0.014062798906423786\n",
      "train loss:0.10949180478454096\n",
      "train loss:0.02729119693433959\n",
      "train loss:0.04525973496073472\n",
      "train loss:0.029526623844891037\n",
      "train loss:0.04241035713520037\n",
      "train loss:0.03365136695065421\n",
      "train loss:0.09121886968400301\n",
      "train loss:0.018349957790408985\n",
      "train loss:0.03603622335276954\n",
      "train loss:0.01889424993143575\n",
      "train loss:0.01920289767547557\n",
      "train loss:0.09751228905840781\n",
      "train loss:0.12315346615345275\n",
      "train loss:0.044689530693605824\n",
      "train loss:0.02796852906528378\n",
      "train loss:0.0064175422398394695\n",
      "train loss:0.03991781326598258\n",
      "train loss:0.020371104487875272\n",
      "train loss:0.08501281609356229\n",
      "train loss:0.05947840255646683\n",
      "train loss:0.04227778579176142\n",
      "train loss:0.020905026214046683\n",
      "train loss:0.006814818658661316\n",
      "train loss:0.058168818700243825\n",
      "train loss:0.011768992391066997\n",
      "train loss:0.03702473446130419\n",
      "train loss:0.028806828514226116\n",
      "train loss:0.02031453590675804\n",
      "train loss:0.0108438571794779\n",
      "train loss:0.08677417456389401\n",
      "train loss:0.09813468788658597\n",
      "train loss:0.0547637154394356\n",
      "train loss:0.029719521085040692\n",
      "train loss:0.012357601956715654\n",
      "train loss:0.06607793168896813\n",
      "train loss:0.09721237878081546\n",
      "train loss:0.0750835825646083\n",
      "train loss:0.06305972550524973\n",
      "train loss:0.011539402428958756\n",
      "train loss:0.09382573695125673\n",
      "train loss:0.07571014401892646\n",
      "train loss:0.07756242253471039\n",
      "train loss:0.07546443921894183\n",
      "train loss:0.038145670494825666\n",
      "train loss:0.024283995629774315\n",
      "train loss:0.07608965411789621\n",
      "train loss:0.05869473144905053\n",
      "train loss:0.008534052458674512\n",
      "train loss:0.04992384167995304\n",
      "train loss:0.012495930419196817\n",
      "train loss:0.053671804846592\n",
      "train loss:0.008391686046866777\n",
      "train loss:0.03650734429777286\n",
      "train loss:0.04142495070734037\n",
      "train loss:0.025684050761199076\n",
      "train loss:0.024487399393095834\n",
      "train loss:0.10502809254769155\n",
      "train loss:0.028620881531659106\n",
      "train loss:0.0298406470693689\n",
      "train loss:0.023059709740377632\n",
      "train loss:0.0760917665716781\n",
      "train loss:0.07977167751469244\n",
      "train loss:0.007475010685613983\n",
      "train loss:0.07108842039981625\n",
      "train loss:0.018070364778626086\n",
      "train loss:0.061506552848015913\n",
      "train loss:0.007557364998272108\n",
      "train loss:0.018733840484241968\n",
      "train loss:0.010053560418452939\n",
      "train loss:0.024525370156982654\n",
      "train loss:0.03986866026490617\n",
      "train loss:0.04164014179747744\n",
      "train loss:0.042421624924312756\n",
      "train loss:0.07271030593955007\n",
      "train loss:0.021525727138850162\n",
      "train loss:0.02115046675928269\n",
      "train loss:0.016600275815928957\n",
      "train loss:0.04222554200040911\n",
      "train loss:0.020938589706917043\n",
      "train loss:0.052640994992622404\n",
      "train loss:0.05283193918445101\n",
      "train loss:0.046907116587080015\n",
      "train loss:0.06329592308907957\n",
      "train loss:0.0482479798301366\n",
      "train loss:0.013775677207778387\n",
      "train loss:0.03135269813543697\n",
      "train loss:0.03609339919991194\n",
      "train loss:0.058294698269182744\n",
      "train loss:0.02912713043431078\n",
      "train loss:0.06158909862022994\n",
      "train loss:0.049125469278028924\n",
      "train loss:0.0317049113077772\n",
      "train loss:0.07889671646954534\n",
      "train loss:0.025606703074219323\n",
      "train loss:0.04812886629863213\n",
      "train loss:0.043527332249208565\n",
      "train loss:0.05111453028976148\n",
      "train loss:0.036683682883960865\n",
      "train loss:0.0991321648931941\n",
      "train loss:0.013169736162296917\n",
      "train loss:0.016098024627105953\n",
      "train loss:0.05490170999254972\n",
      "train loss:0.01706046726035801\n",
      "train loss:0.03411787705807701\n",
      "train loss:0.01754185996498196\n",
      "train loss:0.02690209634015907\n",
      "train loss:0.01507449407013828\n",
      "train loss:0.014572389944115789\n",
      "train loss:0.027789001291212437\n",
      "train loss:0.07010962517771228\n",
      "train loss:0.026532683037266663\n",
      "train loss:0.016841867329277057\n",
      "train loss:0.006535772414061507\n",
      "train loss:0.01555797191124801\n",
      "train loss:0.038079645364038475\n",
      "train loss:0.038907868706648994\n",
      "train loss:0.010717452665585533\n",
      "train loss:0.04269256344936461\n",
      "train loss:0.06523787440873967\n",
      "train loss:0.02544344997040943\n",
      "train loss:0.016656240237373714\n",
      "train loss:0.05376785577169839\n",
      "train loss:0.019981553524071046\n",
      "train loss:0.07958396872739945\n",
      "train loss:0.010839446009413693\n",
      "train loss:0.05432162012511247\n",
      "train loss:0.022338132946683874\n",
      "train loss:0.01604712021515059\n",
      "train loss:0.008957963132389796\n",
      "train loss:0.016495925045646353\n",
      "train loss:0.020089303133498923\n",
      "train loss:0.047916619985846565\n",
      "train loss:0.061345591377818254\n",
      "train loss:0.06763074163757297\n",
      "train loss:0.014627657821738528\n",
      "train loss:0.016289986753721238\n",
      "train loss:0.10860197766120333\n",
      "train loss:0.009031475966527414\n",
      "train loss:0.04461587254089989\n",
      "train loss:0.011636930239326469\n",
      "train loss:0.008103173745911548\n",
      "train loss:0.040771331637196234\n",
      "train loss:0.025935898785202353\n",
      "train loss:0.09393491374844866\n",
      "train loss:0.004635693332597807\n",
      "train loss:0.009355474070327396\n",
      "train loss:0.010814680339457403\n",
      "train loss:0.01069191656809828\n",
      "train loss:0.0121771855818416\n",
      "train loss:0.022545643510162715\n",
      "train loss:0.022205480994439107\n",
      "train loss:0.015232330651970263\n",
      "train loss:0.014016978888546767\n",
      "train loss:0.058415518098211994\n",
      "train loss:0.024517283104603976\n",
      "train loss:0.039779440695397746\n",
      "train loss:0.004938580007677139\n",
      "train loss:0.012215954774097239\n",
      "train loss:0.09090194945970544\n",
      "train loss:0.019072276739951304\n",
      "train loss:0.012221746610822499\n",
      "train loss:0.010102768448253491\n",
      "train loss:0.010532322290504416\n",
      "train loss:0.030233895084770007\n",
      "train loss:0.01942786309644188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.010683275573227959\n",
      "train loss:0.026429983497800614\n",
      "train loss:0.0479063079308812\n",
      "train loss:0.03960016335608821\n",
      "train loss:0.013802052043149765\n",
      "train loss:0.018533506726135435\n",
      "train loss:0.03436079254548619\n",
      "train loss:0.044990295799414444\n",
      "train loss:0.022153722830252756\n",
      "train loss:0.012308597583997575\n",
      "train loss:0.03125905914997928\n",
      "train loss:0.02293648876884562\n",
      "train loss:0.02517468036296048\n",
      "train loss:0.019957756840311078\n",
      "train loss:0.005425079730320079\n",
      "train loss:0.046446006322304466\n",
      "train loss:0.016708539487843566\n",
      "train loss:0.017336434152560906\n",
      "train loss:0.018903163526495004\n",
      "train loss:0.018113233410388528\n",
      "train loss:0.05384447937286785\n",
      "train loss:0.08211153274320283\n",
      "train loss:0.05854756071160888\n",
      "=== epoch:5, train acc:0.985, test acc:0.98 ===\n",
      "train loss:0.012685612584512196\n",
      "train loss:0.017736114306728397\n",
      "train loss:0.0582819990849464\n",
      "train loss:0.07024600462143504\n",
      "train loss:0.030636102148620864\n",
      "train loss:0.007633287096988468\n",
      "train loss:0.012598845161715768\n",
      "train loss:0.014089604663401332\n",
      "train loss:0.040748447282097075\n",
      "train loss:0.06118066497305366\n",
      "train loss:0.025182106116184197\n",
      "train loss:0.14113409424453013\n",
      "train loss:0.024329190698793003\n",
      "train loss:0.018511693858622644\n",
      "train loss:0.021459441299049215\n",
      "train loss:0.053341907653279216\n",
      "train loss:0.037011610417369056\n",
      "train loss:0.0623464103551112\n",
      "train loss:0.04329160594198869\n",
      "train loss:0.030870381718522754\n",
      "train loss:0.021392082523210263\n",
      "train loss:0.06192686804441253\n",
      "train loss:0.06063719217580135\n",
      "train loss:0.029712141711928722\n",
      "train loss:0.012596229513130188\n",
      "train loss:0.02550035787562529\n",
      "train loss:0.035550513287375934\n",
      "train loss:0.013750118014710554\n",
      "train loss:0.020737493023070867\n",
      "train loss:0.011920695798369992\n",
      "train loss:0.06833670805655345\n",
      "train loss:0.012521767416443943\n",
      "train loss:0.07823093992482304\n",
      "train loss:0.06455931132394145\n",
      "train loss:0.03753229310064525\n",
      "train loss:0.007046228761483909\n",
      "train loss:0.05985011663131267\n",
      "train loss:0.07860462372068172\n",
      "train loss:0.03735377757819264\n",
      "train loss:0.015877800726629185\n",
      "train loss:0.014834739740810851\n",
      "train loss:0.07334375982065824\n",
      "train loss:0.02335031007812338\n",
      "train loss:0.047926069324275206\n",
      "train loss:0.028049401556540093\n",
      "train loss:0.009528258329284545\n",
      "train loss:0.01504320496777594\n",
      "train loss:0.01697468088801772\n",
      "train loss:0.027455148737703494\n",
      "train loss:0.039620988462697494\n",
      "train loss:0.008817954244151128\n",
      "train loss:0.02359701363062044\n",
      "train loss:0.0938095283891578\n",
      "train loss:0.05087008734124428\n",
      "train loss:0.03609095304263144\n",
      "train loss:0.030156772595389313\n",
      "train loss:0.02327881642014357\n",
      "train loss:0.012769404518146463\n",
      "train loss:0.01839419385504026\n",
      "train loss:0.0451444165888734\n",
      "train loss:0.028346974221686336\n",
      "train loss:0.03221478308809322\n",
      "train loss:0.0515787899729076\n",
      "train loss:0.030812207261720907\n",
      "train loss:0.011384072201513069\n",
      "train loss:0.13211811844843901\n",
      "train loss:0.010764297832668978\n",
      "train loss:0.02172676006044075\n",
      "train loss:0.008436527985202048\n",
      "train loss:0.019742803574110977\n",
      "train loss:0.029227653154282652\n",
      "train loss:0.013135308526707716\n",
      "train loss:0.01705488512847253\n",
      "train loss:0.025992657838070837\n",
      "train loss:0.05000007060633085\n",
      "train loss:0.008328657639618356\n",
      "train loss:0.029114280119693386\n",
      "train loss:0.021480369077252256\n",
      "train loss:0.05057051232351705\n",
      "train loss:0.017805556726121854\n",
      "train loss:0.039730697075114854\n",
      "train loss:0.018734511359259857\n",
      "train loss:0.01623262714268677\n",
      "train loss:0.017854656756595623\n",
      "train loss:0.10001738222084096\n",
      "train loss:0.026984749976495803\n",
      "train loss:0.07038456757955049\n",
      "train loss:0.013204914318402476\n",
      "train loss:0.03977283409042813\n",
      "train loss:0.10552060744374474\n",
      "train loss:0.019946113539598763\n",
      "train loss:0.014115281616518684\n",
      "train loss:0.040735417657941975\n",
      "train loss:0.09366347830646111\n",
      "train loss:0.06676626384919712\n",
      "train loss:0.04049911021898596\n",
      "train loss:0.05834086237517697\n",
      "train loss:0.09515144929212199\n",
      "train loss:0.10177971707022668\n",
      "train loss:0.004410834838686879\n",
      "train loss:0.03274115717560158\n",
      "train loss:0.05843968185878135\n",
      "train loss:0.019218447412144637\n",
      "train loss:0.012669312994412827\n",
      "train loss:0.03661966004824152\n",
      "train loss:0.03317645754730755\n",
      "train loss:0.086337048598549\n",
      "train loss:0.05557094046537485\n",
      "train loss:0.04845385478023558\n",
      "train loss:0.018301741436904287\n",
      "train loss:0.07873779591137683\n",
      "train loss:0.06733823947260098\n",
      "train loss:0.01456704260845408\n",
      "train loss:0.012836931103046416\n",
      "train loss:0.03671532217501843\n",
      "train loss:0.0025188474166878538\n",
      "train loss:0.014627191679513487\n",
      "train loss:0.07786891931552378\n",
      "train loss:0.008551165043754343\n",
      "train loss:0.026754990914148426\n",
      "train loss:0.013953180732611082\n",
      "train loss:0.07384084405816776\n",
      "train loss:0.06908452417486478\n",
      "train loss:0.0479836981352625\n",
      "train loss:0.03699559990590631\n",
      "train loss:0.018741942516481286\n",
      "train loss:0.028745997611890006\n",
      "train loss:0.016869212716979467\n",
      "train loss:0.01704239964382962\n",
      "train loss:0.04642342205721599\n",
      "train loss:0.008918921248140192\n",
      "train loss:0.01959754424105225\n",
      "train loss:0.004392431989717877\n",
      "train loss:0.022855817621198322\n",
      "train loss:0.023265452466957322\n",
      "train loss:0.03555899330057256\n",
      "train loss:0.01921765864231557\n",
      "train loss:0.013374963033147195\n",
      "train loss:0.017500971101664587\n",
      "train loss:0.09830663302198962\n",
      "train loss:0.04802520024249327\n",
      "train loss:0.04445627109576236\n",
      "train loss:0.08072874319007145\n",
      "train loss:0.050513136303390896\n",
      "train loss:0.05268006906340588\n",
      "train loss:0.03836237108281719\n",
      "train loss:0.013995816741746816\n",
      "train loss:0.08580277366060857\n",
      "train loss:0.008903658104200003\n",
      "train loss:0.057401599432417044\n",
      "train loss:0.06713497677274644\n",
      "train loss:0.00991370709277452\n",
      "train loss:0.006877561205142388\n",
      "train loss:0.03364736788351823\n",
      "train loss:0.022022026365782054\n",
      "train loss:0.033333115349880524\n",
      "train loss:0.03164285307376654\n",
      "train loss:0.05219333511603399\n",
      "train loss:0.04837027648541905\n",
      "train loss:0.020501951802563756\n",
      "train loss:0.014695276470053874\n",
      "train loss:0.06024646516616307\n",
      "train loss:0.03417557122535027\n",
      "train loss:0.055031508587488884\n",
      "train loss:0.03860791828830524\n",
      "train loss:0.030468104611107293\n",
      "train loss:0.023356221749057965\n",
      "train loss:0.01344612773803651\n",
      "train loss:0.00788584415589912\n",
      "train loss:0.02092355212319516\n",
      "train loss:0.020763714263008638\n",
      "train loss:0.03709845338763733\n",
      "train loss:0.03995617535856407\n",
      "train loss:0.0436566243652109\n",
      "train loss:0.027824726046339\n",
      "train loss:0.02360691565864708\n",
      "train loss:0.10209757273561673\n",
      "train loss:0.021100408889518345\n",
      "train loss:0.00932285184975842\n",
      "train loss:0.10237516564850126\n",
      "train loss:0.023568369101465505\n",
      "train loss:0.05115492775155103\n",
      "train loss:0.03774479695059461\n",
      "train loss:0.08039185703148705\n",
      "train loss:0.03746688792263699\n",
      "train loss:0.03893722676948522\n",
      "train loss:0.0818558958314179\n",
      "train loss:0.041943369498571824\n",
      "train loss:0.016430491926922978\n",
      "train loss:0.007273970142380726\n",
      "train loss:0.018753680470939487\n",
      "train loss:0.03665055327845666\n",
      "train loss:0.027253040576960798\n",
      "train loss:0.021474029858087808\n",
      "train loss:0.0891010966456713\n",
      "train loss:0.05129100554096306\n",
      "train loss:0.026918426933832777\n",
      "train loss:0.02816429926908822\n",
      "train loss:0.04610241772138446\n",
      "train loss:0.01736798159989893\n",
      "train loss:0.020048868454267864\n",
      "train loss:0.03708753190582205\n",
      "train loss:0.006916065572611534\n",
      "train loss:0.0760082280318498\n",
      "train loss:0.02096086760930542\n",
      "train loss:0.03129389458892475\n",
      "train loss:0.05670733251258124\n",
      "train loss:0.03181145825762416\n",
      "train loss:0.023534469758512165\n",
      "train loss:0.01931890574136928\n",
      "train loss:0.05977557506992977\n",
      "train loss:0.04590233325692178\n",
      "train loss:0.03728422266097696\n",
      "train loss:0.03409563057254977\n",
      "train loss:0.06458118915742089\n",
      "train loss:0.01415904887358722\n",
      "train loss:0.03389135458356001\n",
      "train loss:0.03024487265565791\n",
      "train loss:0.01097364690198684\n",
      "train loss:0.09636359512135623\n",
      "train loss:0.007855861314649304\n",
      "train loss:0.00626321109161797\n",
      "train loss:0.019954368587114104\n",
      "train loss:0.029770105667647644\n",
      "train loss:0.02222881931579265\n",
      "train loss:0.11975927385808831\n",
      "train loss:0.01114645275804096\n",
      "train loss:0.00921403641169381\n",
      "train loss:0.015036066524073648\n",
      "train loss:0.012736910885691694\n",
      "train loss:0.047149893938643\n",
      "train loss:0.01873342986744625\n",
      "train loss:0.07367072838714823\n",
      "train loss:0.02344104157671469\n",
      "train loss:0.013724142960523716\n",
      "train loss:0.029209128698186673\n",
      "train loss:0.027505833575004867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.049951468331862155\n",
      "train loss:0.03759374742756121\n",
      "train loss:0.028037112574112268\n",
      "train loss:0.03642866379922708\n",
      "train loss:0.04546507703911124\n",
      "train loss:0.011805444854546576\n",
      "train loss:0.020648346965029568\n",
      "train loss:0.05315019441567581\n",
      "train loss:0.038629127815714384\n",
      "train loss:0.01857058835540163\n",
      "train loss:0.007328874038876585\n",
      "train loss:0.04958871265152813\n",
      "train loss:0.08142161368124551\n",
      "train loss:0.03452067273272707\n",
      "train loss:0.01909327029856125\n",
      "train loss:0.020800497022519012\n",
      "train loss:0.07089166061239939\n",
      "train loss:0.03931216503737531\n",
      "train loss:0.07447737016007078\n",
      "train loss:0.036021561553107685\n",
      "train loss:0.13187443429939674\n",
      "train loss:0.012317559125931592\n",
      "train loss:0.021028727138479274\n",
      "train loss:0.03678569193298107\n",
      "train loss:0.010293666520509705\n",
      "train loss:0.020121305628626754\n",
      "train loss:0.017807995709241145\n",
      "train loss:0.009822646884250939\n",
      "train loss:0.009745321824163574\n",
      "train loss:0.048020320770868506\n",
      "train loss:0.03428464866764395\n",
      "train loss:0.031584745567285424\n",
      "train loss:0.08817451971167589\n",
      "train loss:0.010396897917873342\n",
      "train loss:0.01623850936587903\n",
      "train loss:0.025968180807478446\n",
      "train loss:0.004064047257081959\n",
      "train loss:0.021217759036628158\n",
      "train loss:0.09832527175341949\n",
      "train loss:0.022593637018653977\n",
      "train loss:0.07647035450514907\n",
      "train loss:0.024442125823697022\n",
      "train loss:0.00678719555115557\n",
      "train loss:0.014521538643247421\n",
      "train loss:0.03540521730143551\n",
      "train loss:0.059381631450630634\n",
      "train loss:0.015224513070079087\n",
      "train loss:0.014033789986138743\n",
      "train loss:0.06457949657926011\n",
      "train loss:0.013762976992527305\n",
      "train loss:0.06914058055360882\n",
      "train loss:0.021163370658136862\n",
      "train loss:0.00966396243786532\n",
      "train loss:0.04107410392011962\n",
      "train loss:0.015532145930623138\n",
      "train loss:0.054073266235316116\n",
      "train loss:0.03976438909786688\n",
      "train loss:0.039140076465263206\n",
      "train loss:0.049754896399426575\n",
      "train loss:0.0372421133203613\n",
      "train loss:0.039556497087048975\n",
      "train loss:0.020813656122252947\n",
      "train loss:0.03913519687588898\n",
      "train loss:0.013494739915629056\n",
      "train loss:0.004008891868381272\n",
      "train loss:0.09991991948488271\n",
      "train loss:0.06872945643509366\n",
      "train loss:0.03132393609815914\n",
      "train loss:0.07765643202929497\n",
      "train loss:0.010204432599615985\n",
      "train loss:0.0925579569140456\n",
      "train loss:0.05462393876838573\n",
      "train loss:0.025476607736904664\n",
      "train loss:0.01101434815357178\n",
      "train loss:0.003823876204402354\n",
      "train loss:0.028582214240861187\n",
      "train loss:0.023020438055735976\n",
      "train loss:0.02447638373142471\n",
      "train loss:0.0288658224719956\n",
      "train loss:0.026170461903804555\n",
      "train loss:0.016620042639959188\n",
      "train loss:0.03208948066903676\n",
      "train loss:0.07041746315748229\n",
      "train loss:0.012085221147542296\n",
      "train loss:0.021865533238460896\n",
      "train loss:0.005311483011410065\n",
      "train loss:0.018758431676260387\n",
      "train loss:0.007462748938457472\n",
      "train loss:0.029630795473386987\n",
      "train loss:0.014963844748633331\n",
      "train loss:0.03784759558040387\n",
      "train loss:0.045148028091371216\n",
      "train loss:0.014995123233070227\n",
      "train loss:0.04697394967832496\n",
      "train loss:0.007955036182908383\n",
      "train loss:0.020002783617380882\n",
      "train loss:0.0528163231195782\n",
      "train loss:0.044492566258166714\n",
      "train loss:0.013794945002667853\n",
      "train loss:0.010656141815080702\n",
      "train loss:0.07328556929024303\n",
      "train loss:0.0021989733463815375\n",
      "train loss:0.013722118850398653\n",
      "train loss:0.014152962920879177\n",
      "train loss:0.02761321032616637\n",
      "train loss:0.09446674050631046\n",
      "train loss:0.027503091129594325\n",
      "train loss:0.0885863096390147\n",
      "train loss:0.0184206692290809\n",
      "train loss:0.008355876435564374\n",
      "train loss:0.015349133844971299\n",
      "train loss:0.0669171268067887\n",
      "train loss:0.004037407932122025\n",
      "train loss:0.02899720029471185\n",
      "train loss:0.03696446346552994\n",
      "train loss:0.02043206093218977\n",
      "train loss:0.05112402591606782\n",
      "train loss:0.042406902448164946\n",
      "train loss:0.031019709964704295\n",
      "train loss:0.03443830527295663\n",
      "train loss:0.020741124330281403\n",
      "train loss:0.022795528741501384\n",
      "train loss:0.03749370948575958\n",
      "train loss:0.04374728570807893\n",
      "train loss:0.03153238015437242\n",
      "train loss:0.029045051171689935\n",
      "train loss:0.016824408851604817\n",
      "train loss:0.009534459998105234\n",
      "train loss:0.03263284190912572\n",
      "train loss:0.10727060404882083\n",
      "train loss:0.02197268332108555\n",
      "train loss:0.02343132991845114\n",
      "train loss:0.05459637503510873\n",
      "train loss:0.012905510938739779\n",
      "train loss:0.022744321140863884\n",
      "train loss:0.054123474227802525\n",
      "train loss:0.05497860448101192\n",
      "train loss:0.015010469785187504\n",
      "train loss:0.04446650121553567\n",
      "train loss:0.021392790063668805\n",
      "train loss:0.013237548276232016\n",
      "train loss:0.010783645926760788\n",
      "train loss:0.011917643742339432\n",
      "train loss:0.026342760753749927\n",
      "train loss:0.010087194766155489\n",
      "train loss:0.010562118459688052\n",
      "train loss:0.006500713171332356\n",
      "train loss:0.017148548550642063\n",
      "train loss:0.047763050342365325\n",
      "train loss:0.18821471780665633\n",
      "train loss:0.009744209088028982\n",
      "train loss:0.010181897314318608\n",
      "train loss:0.013378116670141816\n",
      "train loss:0.046943338373227374\n",
      "train loss:0.010933759128154625\n",
      "train loss:0.014820925453466683\n",
      "train loss:0.08444586124267671\n",
      "train loss:0.023923320204243707\n",
      "train loss:0.023609738473901132\n",
      "train loss:0.00909765377945612\n",
      "train loss:0.06716309835951187\n",
      "train loss:0.006524060905494006\n",
      "train loss:0.05161052074129208\n",
      "train loss:0.045709594240900174\n",
      "train loss:0.03886264791073149\n",
      "train loss:0.016368742214288676\n",
      "train loss:0.038294722180021674\n",
      "train loss:0.014734304788464343\n",
      "train loss:0.05291796062890473\n",
      "train loss:0.008657859535895764\n",
      "train loss:0.021179357760953494\n",
      "train loss:0.01222862094547707\n",
      "train loss:0.0071751682482771835\n",
      "train loss:0.011757139275001018\n",
      "train loss:0.013865348874289498\n",
      "train loss:0.030486925578221698\n",
      "train loss:0.02041134182145227\n",
      "train loss:0.02923950953755784\n",
      "train loss:0.018898782067679754\n",
      "train loss:0.007202224516777587\n",
      "train loss:0.008013114254871567\n",
      "train loss:0.03302577728973144\n",
      "train loss:0.009666481575138003\n",
      "train loss:0.057937268929308845\n",
      "train loss:0.021774645026031728\n",
      "train loss:0.048054324354140615\n",
      "train loss:0.005194993933680163\n",
      "train loss:0.16285609777089483\n",
      "train loss:0.009846513946197136\n",
      "train loss:0.016299091502020358\n",
      "train loss:0.01220345519854016\n",
      "train loss:0.007973098990993454\n",
      "train loss:0.002711016372463351\n",
      "train loss:0.05387582813260797\n",
      "train loss:0.005465698893607187\n",
      "train loss:0.019568387600243358\n",
      "train loss:0.009972813547174796\n",
      "train loss:0.010361847164496814\n",
      "train loss:0.06523505708918231\n",
      "train loss:0.015445727772470988\n",
      "train loss:0.10495367069566859\n",
      "train loss:0.009049932897519226\n",
      "train loss:0.014850311251502917\n",
      "train loss:0.04187511329088038\n",
      "train loss:0.00676102934754289\n",
      "train loss:0.02861657429220088\n",
      "train loss:0.0026961167191469943\n",
      "train loss:0.028070361699569744\n",
      "train loss:0.012487107877074488\n",
      "train loss:0.05524674578741005\n",
      "train loss:0.014628817708255248\n",
      "train loss:0.16175722405401186\n",
      "train loss:0.021578432045395807\n",
      "train loss:0.04161391682861223\n",
      "train loss:0.03288026639736167\n",
      "train loss:0.013321747504567447\n",
      "train loss:0.030176920469825536\n",
      "train loss:0.016859957807925707\n",
      "train loss:0.02279202914280444\n",
      "train loss:0.012457258836934056\n",
      "train loss:0.005013966071617965\n",
      "train loss:0.026995659062129414\n",
      "train loss:0.021351912586817595\n",
      "train loss:0.05003053715952173\n",
      "train loss:0.06786247206291356\n",
      "train loss:0.12420302628155402\n",
      "train loss:0.004267859457186611\n",
      "train loss:0.12278936693635176\n",
      "train loss:0.034219063675453965\n",
      "train loss:0.021745707602941318\n",
      "train loss:0.007286336216345148\n",
      "train loss:0.012558118347826048\n",
      "train loss:0.012732557532414748\n",
      "train loss:0.014678019690424822\n",
      "train loss:0.02649594882102651\n",
      "train loss:0.06008020867362549\n",
      "train loss:0.005007794362862809\n",
      "train loss:0.00229729840624621\n",
      "train loss:0.015518535543264416\n",
      "train loss:0.06117922881227309\n",
      "train loss:0.026756794837748763\n",
      "train loss:0.014386134565573812\n",
      "train loss:0.03481283889704077\n",
      "train loss:0.058386744452434546\n",
      "train loss:0.019010245748392194\n",
      "train loss:0.01849384081738756\n",
      "train loss:0.01850779816616379\n",
      "train loss:0.06506470487721701\n",
      "train loss:0.04761809982645835\n",
      "train loss:0.010180769793899038\n",
      "train loss:0.006044281151007863\n",
      "train loss:0.013713591176419772\n",
      "train loss:0.01386669436486143\n",
      "train loss:0.005775442525358582\n",
      "train loss:0.0029940611525680573\n",
      "train loss:0.021246937574972168\n",
      "train loss:0.0730839870061973\n",
      "train loss:0.06457415609072097\n",
      "train loss:0.06425028867480047\n",
      "train loss:0.02707408829894157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.01438744558467265\n",
      "train loss:0.012600840289602117\n",
      "train loss:0.013106143160524204\n",
      "train loss:0.009806284511337264\n",
      "train loss:0.014126522681171238\n",
      "train loss:0.027994000871906878\n",
      "train loss:0.04490417834071542\n",
      "train loss:0.01197043881240461\n",
      "train loss:0.012735114027455738\n",
      "train loss:0.034169579832417515\n",
      "train loss:0.018044187467578764\n",
      "train loss:0.07268198703730504\n",
      "train loss:0.0942853384393305\n",
      "train loss:0.037861976814805735\n",
      "train loss:0.01790610488058142\n",
      "train loss:0.026834667819230114\n",
      "train loss:0.010596026248752917\n",
      "train loss:0.030375370408864483\n",
      "train loss:0.012206389976536796\n",
      "train loss:0.04629175726005874\n",
      "train loss:0.020496749768767683\n",
      "train loss:0.02890462688348313\n",
      "train loss:0.01011587738163687\n",
      "train loss:0.054964986309374346\n",
      "train loss:0.0265039216445528\n",
      "train loss:0.006695610435100697\n",
      "train loss:0.006496201454403308\n",
      "train loss:0.021733394746993585\n",
      "train loss:0.058825530637534464\n",
      "train loss:0.02277378397864917\n",
      "train loss:0.015213197820028824\n",
      "train loss:0.02251358619493177\n",
      "train loss:0.03190867459922771\n",
      "train loss:0.006837265829443942\n",
      "train loss:0.031445391206622444\n",
      "train loss:0.016149191055510825\n",
      "train loss:0.00747267135409963\n",
      "train loss:0.005129329476898956\n",
      "train loss:0.007687173449841695\n",
      "train loss:0.011688408659382137\n",
      "train loss:0.018002053599973873\n",
      "train loss:0.025295924364888648\n",
      "train loss:0.04837536246008556\n",
      "train loss:0.025817025948059416\n",
      "train loss:0.014791534456238629\n",
      "train loss:0.05354744646968844\n",
      "train loss:0.09130501147689167\n",
      "train loss:0.014943131616711937\n",
      "train loss:0.0031194821117777865\n",
      "train loss:0.018162956012867396\n",
      "train loss:0.024104048892362763\n",
      "train loss:0.025556560112588715\n",
      "train loss:0.01562024001400802\n",
      "train loss:0.05719611757856842\n",
      "train loss:0.03395542151069257\n",
      "train loss:0.009725194785088143\n",
      "train loss:0.012042814628666394\n",
      "train loss:0.003545344714067827\n",
      "train loss:0.028866989110629408\n",
      "train loss:0.015964764872510154\n",
      "train loss:0.016649429012916953\n",
      "train loss:0.020118255291357186\n",
      "train loss:0.012330156464050364\n",
      "train loss:0.01900809002823569\n",
      "train loss:0.013907872937108146\n",
      "train loss:0.021836299532697626\n",
      "train loss:0.007651971192152043\n",
      "train loss:0.02018226387574357\n",
      "train loss:0.04565746746607836\n",
      "train loss:0.03623851314690771\n",
      "train loss:0.010811136946528101\n",
      "train loss:0.002873859517965347\n",
      "train loss:0.015399653562845703\n",
      "train loss:0.06061613783702846\n",
      "train loss:0.018455210537323345\n",
      "train loss:0.0064523054518991416\n",
      "train loss:0.018853244310743547\n",
      "train loss:0.015643021013842174\n",
      "train loss:0.06087270907332789\n",
      "train loss:0.020331301729056922\n",
      "train loss:0.02982774005117642\n",
      "train loss:0.03340716382219252\n",
      "train loss:0.006270174940147718\n",
      "train loss:0.007417630960369269\n",
      "train loss:0.01681394133632642\n",
      "train loss:0.02830516833388368\n",
      "train loss:0.015992416903583904\n",
      "train loss:0.038342909486220364\n",
      "train loss:0.06038465275973071\n",
      "train loss:0.010631006879786555\n",
      "train loss:0.003880977746181804\n",
      "train loss:0.0857346966438514\n",
      "train loss:0.031338133614980536\n",
      "train loss:0.008003156028176901\n",
      "train loss:0.014615797342304282\n",
      "train loss:0.011813845291815405\n",
      "train loss:0.04025215212589892\n",
      "train loss:0.036955640395482214\n",
      "train loss:0.005771558732235809\n",
      "train loss:0.021837263037027915\n",
      "train loss:0.06481013216789361\n",
      "train loss:0.013080614866090523\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.9846\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# データの読み込み\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# 処理に時間のかかる場合はデータを削減 \n",
    "#x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "#x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 5\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "                        \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# グラフの描画\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
